{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the timestamp and a given message\n",
    "def log(txt):\n",
    "    print(datetime.utcnow(), txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unigram counts of all words in positive and negative reviews\n",
    "# splits the given data into n sections\n",
    "def split_n(training_data, n):\n",
    "    sections = [[] * n]\n",
    "    i = 0\n",
    "    for sentence in training_data:\n",
    "        sections[i].append(sentence)\n",
    "        i = (i + 1) % n\n",
    "    return sections\n",
    "\n",
    "# builds the vocabulary based off given training data\n",
    "def build_vocab(training_data):\n",
    "    # unigram_dict = {'<UNK>' : 0}\n",
    "    vocabulary = []\n",
    "    for sentence in training_data:\n",
    "        for word in sentence:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    # vocabulary = list(set([word for word in sentence for sentence in training_data]))\n",
    "    vocabulary.sort()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-28 23:20:11.655496 opened files\n2020-02-28 23:20:11.684419 read pos neg data\n2020-02-28 23:20:11.685416 created full data and Y\n2020-02-28 23:20:18.740995 built full vocab\n2020-02-28 23:20:18.740995 building one-hot array\n2020-02-28 23:21:29.702297 one-hot done\n"
    }
   ],
   "source": [
    "# read the positive and negative reviews into one-hot encodings\n",
    "pos_file = open('train_positive_reviews.txt', \"rt\")\n",
    "neg_file = open('train_negative_reviews.txt', \"rt\")\n",
    "log(\"opened files\")\n",
    "pos_data = [sentence.lower().split() for sentence in pos_file.readlines()]\n",
    "neg_data = [sentence.lower().split() for sentence in neg_file.readlines()]\n",
    "log(\"read pos neg data\")\n",
    "full_data = pos_data + neg_data\n",
    "Y = np.array([1] * len(pos_data) + [0] * len(neg_data))\n",
    "log(\"created full data and Y\")\n",
    "\n",
    "full_vocab = build_vocab(full_data)\n",
    "log(\"built full vocab\")\n",
    "\n",
    "log('building one-hot array')\n",
    "hot_ones = np.array([np.array([1 if word in sentence else 0 for word in full_vocab]) for sentence in full_data])\n",
    "log(\"one-hot done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the a model with the given number of weights\n",
    "def make_model(nodes, input_len):\n",
    "    return Sequential([\n",
    "        Dense(nodes, input_dim=input_len, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')])\n",
    "nodes = [100, 200, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " 0.9602\nEpoch 4/5\n7798/7798 [==============================] - 4s 554us/step - loss: 0.0572 - accuracy: 0.9883\nEpoch 5/5\n7798/7798 [==============================] - 4s 565us/step - loss: 0.0254 - accuracy: 0.9965\n2020-02-28 23:24:33.216871 Evaluating model\n866/866 [==============================] - 0s 387us/step\n2020-02-28 23:24:33.772386 Done evaluating, accuracy=0.7378752827644348\n2020-02-28 23:24:33.931959 Splitting test-training data (sentence #9 to test set)\n2020-02-28 23:24:34.549306 Creating model\n2020-02-28 23:24:34.596213 Compiling model\n2020-02-28 23:24:34.648077 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 4s 531us/step - loss: 0.6271 - accuracy: 0.6739\nEpoch 2/5\n7798/7798 [==============================] - 4s 526us/step - loss: 0.3371 - accuracy: 0.8779\nEpoch 3/5\n7798/7798 [==============================] - 5s 641us/step - loss: 0.1436 - accuracy: 0.9604\nEpoch 4/5\n7798/7798 [==============================] - 5s 603us/step - loss: 0.0628 - accuracy: 0.9876\nEpoch 5/5\n7798/7798 [==============================] - 5s 579us/step - loss: 0.0299 - accuracy: 0.9954\n2020-02-28 23:24:58.703254 Evaluating model\n866/866 [==============================] - 0s 400us/step\n2020-02-28 23:24:59.282755 Done evaluating, accuracy=0.7632794380187988\n2020-02-28 23:24:59.442324 Splitting test-training data (sentence #10 to test set)\n2020-02-28 23:24:59.910431 Creating model\n2020-02-28 23:24:59.962934 Compiling model\n2020-02-28 23:25:00.023771 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 4s 549us/step - loss: 0.6289 - accuracy: 0.6752\nEpoch 2/5\n7798/7798 [==============================] - 4s 542us/step - loss: 0.3362 - accuracy: 0.8750\nEpoch 3/5\n7798/7798 [==============================] - 4s 532us/step - loss: 0.1368 - accuracy: 0.9617\nEpoch 4/5\n7798/7798 [==============================] - 4s 534us/step - loss: 0.0597 - accuracy: 0.9869\nEpoch 5/5\n7798/7798 [==============================] - 4s 538us/step - loss: 0.0279 - accuracy: 0.9963\n2020-02-28 23:25:22.637194 Evaluating model\n866/866 [==============================] - 0s 420us/step\n2020-02-28 23:25:23.237588 Done evaluating, accuracy=0.7621247172355652\n2020-02-28 23:25:23.389218 Splitting test-training data (sentence #1 to test set)\n2020-02-28 23:25:23.842005 Creating model\n2020-02-28 23:25:23.890840 Compiling model\n2020-02-28 23:25:23.952674 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 6s 784us/step - loss: 0.6077 - accuracy: 0.6804\nEpoch 2/5\n7797/7797 [==============================] - 6s 774us/step - loss: 0.2877 - accuracy: 0.8927\nEpoch 3/5\n7797/7797 [==============================] - 6s 781us/step - loss: 0.1077 - accuracy: 0.9683\nEpoch 4/5\n7797/7797 [==============================] - 6s 796us/step - loss: 0.0419 - accuracy: 0.9914\nEpoch 5/5\n7797/7797 [==============================] - 6s 788us/step - loss: 0.0174 - accuracy: 0.9976\n2020-02-28 23:25:56.386854 Evaluating model\n867/867 [==============================] - 0s 520us/step\n2020-02-28 23:25:57.100943 Done evaluating, accuracy=0.7670127153396606\n2020-02-28 23:25:57.294464 Splitting test-training data (sentence #2 to test set)\n2020-02-28 23:25:57.840997 Creating model\n2020-02-28 23:25:57.893856 Compiling model\n2020-02-28 23:25:57.952668 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 6s 790us/step - loss: 0.6220 - accuracy: 0.6792\nEpoch 2/5\n7797/7797 [==============================] - 6s 776us/step - loss: 0.3090 - accuracy: 0.8885\nEpoch 3/5\n7797/7797 [==============================] - 6s 786us/step - loss: 0.1114 - accuracy: 0.9705\nEpoch 4/5\n7797/7797 [==============================] - 6s 786us/step - loss: 0.0430 - accuracy: 0.9908\nEpoch 5/5\n7797/7797 [==============================] - 6s 788us/step - loss: 0.0164 - accuracy: 0.9981\n2020-02-28 23:26:30.601595 Evaluating model\n867/867 [==============================] - 0s 533us/step\n2020-02-28 23:26:31.325657 Done evaluating, accuracy=0.7370242476463318\n2020-02-28 23:26:31.530145 Splitting test-training data (sentence #3 to test set)\n2020-02-28 23:26:32.099704 Creating model\n2020-02-28 23:26:32.153563 Compiling model\n2020-02-28 23:26:32.217390 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 6s 785us/step - loss: 0.6010 - accuracy: 0.6818\nEpoch 2/5\n7797/7797 [==============================] - 6s 776us/step - loss: 0.2678 - accuracy: 0.9032\nEpoch 3/5\n7797/7797 [==============================] - 6s 783us/step - loss: 0.0888 - accuracy: 0.9761\nEpoch 4/5\n7797/7797 [==============================] - 6s 781us/step - loss: 0.0305 - accuracy: 0.9941\nEpoch 5/5\n7797/7797 [==============================] - 6s 785us/step - loss: 0.0120 - accuracy: 0.9987\n2020-02-28 23:27:04.674962 Evaluating model\n867/867 [==============================] - 0s 545us/step\n2020-02-28 23:27:05.447896 Done evaluating, accuracy=0.7635524868965149\n2020-02-28 23:27:05.636391 Splitting test-training data (sentence #4 to test set)\n2020-02-28 23:27:06.124086 Creating model\n2020-02-28 23:27:06.174878 Compiling model\n2020-02-28 23:27:06.248635 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 6s 788us/step - loss: 0.5987 - accuracy: 0.6887\nEpoch 2/5\n7797/7797 [==============================] - 6s 780us/step - loss: 0.2673 - accuracy: 0.9023\nEpoch 3/5\n7797/7797 [==============================] - 6s 792us/step - loss: 0.0905 - accuracy: 0.9749\nEpoch 4/5\n7797/7797 [==============================] - 6s 785us/step - loss: 0.0330 - accuracy: 0.9941\nEpoch 5/5\n7797/7797 [==============================] - 6s 783us/step - loss: 0.0129 - accuracy: 0.9990\n2020-02-28 23:27:38.915453 Evaluating model\n867/867 [==============================] - 0s 558us/step\n2020-02-28 23:27:39.702345 Done evaluating, accuracy=0.7404844164848328\n2020-02-28 23:27:39.926781 Splitting test-training data (sentence #5 to test set)\n2020-02-28 23:27:40.475309 Creating model\n2020-02-28 23:27:40.529169 Compiling model\n2020-02-28 23:27:40.592994 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 6s 790us/step - loss: 0.6329 - accuracy: 0.6563\nEpoch 2/5\n7798/7798 [==============================] - 6s 776us/step - loss: 0.3289 - accuracy: 0.8780\nEpoch 3/5\n7798/7798 [==============================] - 6s 784us/step - loss: 0.1247 - accuracy: 0.9611\nEpoch 4/5\n7798/7798 [==============================] - 6s 787us/step - loss: 0.0469 - accuracy: 0.9888\nEpoch 5/5\n7798/7798 [==============================] - 6s 789us/step - loss: 0.0188 - accuracy: 0.9973\n2020-02-28 23:28:13.303794 Evaluating model\n866/866 [==============================] - 0s 576us/step\n2020-02-28 23:28:14.127589 Done evaluating, accuracy=0.7598152160644531\n2020-02-28 23:28:14.325059 Splitting test-training data (sentence #6 to test set)\n2020-02-28 23:28:14.800536 Creating model\n2020-02-28 23:28:14.851398 Compiling model\n2020-02-28 23:28:14.913265 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 6s 795us/step - loss: 0.6031 - accuracy: 0.6907\nEpoch 2/5\n7798/7798 [==============================] - 6s 776us/step - loss: 0.2788 - accuracy: 0.9015\nEpoch 3/5\n7798/7798 [==============================] - 6s 787us/step - loss: 0.1044 - accuracy: 0.9710\nEpoch 4/5\n7798/7798 [==============================] - 6s 786us/step - loss: 0.0388 - accuracy: 0.9935\nEpoch 5/5\n7798/7798 [==============================] - 6s 786us/step - loss: 0.0160 - accuracy: 0.9978\n2020-02-28 23:28:47.856167 Evaluating model\n866/866 [==============================] - 1s 593us/step\n2020-02-28 23:28:48.713906 Done evaluating, accuracy=0.7644341588020325\n2020-02-28 23:28:48.932288 Splitting test-training data (sentence #7 to test set)\n2020-02-28 23:28:49.476864 Creating model\n2020-02-28 23:28:49.529722 Compiling model\n2020-02-28 23:28:49.591522 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 6s 802us/step - loss: 0.6084 - accuracy: 0.6953\nEpoch 2/5\n7798/7798 [==============================] - 6s 785us/step - loss: 0.2855 - accuracy: 0.8961\nEpoch 3/5\n7798/7798 [==============================] - 6s 789us/step - loss: 0.1030 - accuracy: 0.9713\nEpoch 4/5\n7798/7798 [==============================] - 6s 788us/step - loss: 0.0385 - accuracy: 0.9933\nEpoch 5/5\n7798/7798 [==============================] - 6s 782us/step - loss: 0.0155 - accuracy: 0.9987\n2020-02-28 23:29:22.573082 Evaluating model\n866/866 [==============================] - 1s 579us/step\n2020-02-28 23:29:23.451731 Done evaluating, accuracy=0.7528868317604065\n2020-02-28 23:29:23.685614 Splitting test-training data (sentence #8 to test set)\n2020-02-28 23:29:24.410778 Creating model\n2020-02-28 23:29:24.481586 Compiling model\n2020-02-28 23:29:24.555389 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 7s 873us/step - loss: 0.5999 - accuracy: 0.6899\nEpoch 2/5\n7798/7798 [==============================] - 7s 843us/step - loss: 0.2802 - accuracy: 0.8963\nEpoch 3/5\n7798/7798 [==============================] - 7s 854us/step - loss: 0.1057 - accuracy: 0.9722\nEpoch 4/5\n7798/7798 [==============================] - 6s 809us/step - loss: 0.0416 - accuracy: 0.9910\nEpoch 5/5\n7798/7798 [==============================] - 7s 888us/step - loss: 0.0171 - accuracy: 0.9982\n2020-02-28 23:30:00.722951 Evaluating model\n866/866 [==============================] - 1s 1ms/step\n2020-02-28 23:30:02.171850 Done evaluating, accuracy=0.7459584474563599\n2020-02-28 23:30:02.686473 Splitting test-training data (sentence #9 to test set)\n2020-02-28 23:30:03.717715 Creating model\n2020-02-28 23:30:03.817447 Compiling model\n2020-02-28 23:30:03.935134 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 6s 804us/step - loss: 0.6162 - accuracy: 0.6781\nEpoch 2/5\n7798/7798 [==============================] - 6s 776us/step - loss: 0.2986 - accuracy: 0.8904\nEpoch 3/5\n7798/7798 [==============================] - 6s 822us/step - loss: 0.1122 - accuracy: 0.9659\nEpoch 4/5\n7798/7798 [==============================] - 7s 843us/step - loss: 0.0442 - accuracy: 0.9909\nEpoch 5/5\n7798/7798 [==============================] - 6s 779us/step - loss: 0.0159 - accuracy: 0.9983\n2020-02-28 23:30:38.969249 Evaluating model\n866/866 [==============================] - 1s 584us/step\n2020-02-28 23:30:39.856908 Done evaluating, accuracy=0.7575057744979858\n2020-02-28 23:30:40.086294 Splitting test-training data (sentence #10 to test set)\n2020-02-28 23:30:40.655780 Creating model\n2020-02-28 23:30:40.709627 Compiling model\n2020-02-28 23:30:40.777445 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 6s 830us/step - loss: 0.6179 - accuracy: 0.6716\nEpoch 2/5\n7798/7798 [==============================] - 6s 791us/step - loss: 0.2973 - accuracy: 0.8922\nEpoch 3/5\n7798/7798 [==============================] - 6s 796us/step - loss: 0.1002 - accuracy: 0.9729\nEpoch 4/5\n7798/7798 [==============================] - 6s 816us/step - loss: 0.0352 - accuracy: 0.9940\nEpoch 5/5\n7798/7798 [==============================] - 7s 838us/step - loss: 0.0133 - accuracy: 0.9990\n2020-02-28 23:31:14.997019 Evaluating model\n866/866 [==============================] - 1s 644us/step\n2020-02-28 23:31:15.995349 Done evaluating, accuracy=0.7575057744979858\n2020-02-28 23:31:16.246742 Splitting test-training data (sentence #1 to test set)\n2020-02-28 23:31:16.788316 Creating model\n2020-02-28 23:31:16.837159 Compiling model\n2020-02-28 23:31:16.897034 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.5940 - accuracy: 0.6973\nEpoch 2/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.2473 - accuracy: 0.9104\nEpoch 3/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0794 - accuracy: 0.9790\nEpoch 4/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0257 - accuracy: 0.9959\nEpoch 5/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0091 - accuracy: 0.9995\n2020-02-28 23:32:02.008508 Evaluating model\n867/867 [==============================] - 1s 727us/step\n2020-02-28 23:32:03.089613 Done evaluating, accuracy=0.769319474697113\n2020-02-28 23:32:03.299052 Splitting test-training data (sentence #2 to test set)\n2020-02-28 23:32:03.860552 Creating model\n2020-02-28 23:32:03.939342 Compiling model\n2020-02-28 23:32:04.046058 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.5899 - accuracy: 0.6954\nEpoch 2/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.2440 - accuracy: 0.9129\nEpoch 3/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0784 - accuracy: 0.9801\nEpoch 4/5\n7797/7797 [==============================] - 10s 1ms/step - loss: 0.0252 - accuracy: 0.9949\nEpoch 5/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0086 - accuracy: 0.9995\n2020-02-28 23:32:51.029934 Evaluating model\n867/867 [==============================] - 1s 696us/step\n2020-02-28 23:32:52.088616 Done evaluating, accuracy=0.7370242476463318\n2020-02-28 23:32:52.404772 Splitting test-training data (sentence #3 to test set)\n2020-02-28 23:32:53.147783 Creating model\n2020-02-28 23:32:53.232557 Compiling model\n2020-02-28 23:32:53.337275 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.5873 - accuracy: 0.6919\nEpoch 2/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.2326 - accuracy: 0.9138\nEpoch 3/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0701 - accuracy: 0.9818\nEpoch 4/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0215 - accuracy: 0.9967\nEpoch 5/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.0083 - accuracy: 0.9994\n2020-02-28 23:33:41.146110 Evaluating model\n867/867 [==============================] - 1s 714us/step\n2020-02-28 23:33:42.231207 Done evaluating, accuracy=0.7670127153396606\n2020-02-28 23:33:42.462623 Splitting test-training data (sentence #4 to test set)\n2020-02-28 23:33:42.968236 Creating model\n2020-02-28 23:33:43.016147 Compiling model\n2020-02-28 23:33:43.076980 Fitting model\nEpoch 1/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.6023 - accuracy: 0.6794\nEpoch 2/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.2716 - accuracy: 0.9000\nEpoch 3/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.0918 - accuracy: 0.9759\nEpoch 4/5\n7797/7797 [==============================] - 9s 1ms/step - loss: 0.0321 - accuracy: 0.9937\nEpoch 5/5\n7797/7797 [==============================] - 8s 1ms/step - loss: 0.0115 - accuracy: 0.9986\n2020-02-28 23:34:27.561292 Evaluating model\n867/867 [==============================] - 1s 745us/step\n2020-02-28 23:34:28.681428 Done evaluating, accuracy=0.7381775975227356\n2020-02-28 23:34:28.965668 Splitting test-training data (sentence #5 to test set)\n2020-02-28 23:34:29.511208 Creating model\n2020-02-28 23:34:29.563069 Compiling model\n2020-02-28 23:34:29.621950 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.6125 - accuracy: 0.6671\nEpoch 2/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.2945 - accuracy: 0.8936\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.1004 - accuracy: 0.9701\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0295 - accuracy: 0.9938\nEpoch 5/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0090 - accuracy: 0.9994\n2020-02-28 23:35:13.665320 Evaluating model\n866/866 [==============================] - 1s 769us/step\n2020-02-28 23:35:14.825216 Done evaluating, accuracy=0.7575057744979858\n2020-02-28 23:35:15.116437 Splitting test-training data (sentence #6 to test set)\n2020-02-28 23:35:15.662976 Creating model\n2020-02-28 23:35:15.712843 Compiling model\n2020-02-28 23:35:15.772682 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.5989 - accuracy: 0.6841\nEpoch 2/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.2578 - accuracy: 0.9032\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0826 - accuracy: 0.9797\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0280 - accuracy: 0.9958\nEpoch 5/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0101 - accuracy: 0.9990\n2020-02-28 23:35:59.845449 Evaluating model\n866/866 [==============================] - 1s 768us/step\n2020-02-28 23:36:01.042245 Done evaluating, accuracy=0.7702078819274902\n2020-02-28 23:36:01.281605 Splitting test-training data (sentence #7 to test set)\n2020-02-28 23:36:01.731541 Creating model\n2020-02-28 23:36:01.783401 Compiling model\n2020-02-28 23:36:01.843201 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.6177 - accuracy: 0.6829\nEpoch 2/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.2992 - accuracy: 0.8892\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.1063 - accuracy: 0.9695\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0370 - accuracy: 0.9919\nEpoch 5/5\n7798/7798 [==============================] - 9s 1ms/step - loss: 0.0132 - accuracy: 0.9986\n2020-02-28 23:36:46.608165 Evaluating model\n866/866 [==============================] - 1s 745us/step\n2020-02-28 23:36:47.808951 Done evaluating, accuracy=0.7621247172355652\n2020-02-28 23:36:48.105159 Splitting test-training data (sentence #8 to test set)\n2020-02-28 23:36:48.646710 Creating model\n2020-02-28 23:36:48.695578 Compiling model\n2020-02-28 23:36:48.754423 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.5868 - accuracy: 0.6965\nEpoch 2/5\n7798/7798 [==============================] - 9s 1ms/step - loss: 0.2342 - accuracy: 0.9137\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0683 - accuracy: 0.9836\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0205 - accuracy: 0.9969\nEpoch 5/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0070 - accuracy: 0.9995\n2020-02-28 23:37:33.589400 Evaluating model\n866/866 [==============================] - 1s 738us/step\n2020-02-28 23:37:34.794175 Done evaluating, accuracy=0.7551963329315186\n2020-02-28 23:37:35.052519 Splitting test-training data (sentence #9 to test set)\n2020-02-28 23:37:35.561126 Creating model\n2020-02-28 23:37:35.610993 Compiling model\n2020-02-28 23:37:35.666874 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.5986 - accuracy: 0.6866\nEpoch 2/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.2728 - accuracy: 0.8995\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0911 - accuracy: 0.9776\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0321 - accuracy: 0.9940\nEpoch 5/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0122 - accuracy: 0.9987\n2020-02-28 23:38:19.938586 Evaluating model\n866/866 [==============================] - 1s 745us/step\n2020-02-28 23:38:21.143363 Done evaluating, accuracy=0.7563510537147522\n2020-02-28 23:38:21.450540 Splitting test-training data (sentence #10 to test set)\n2020-02-28 23:38:22.011085 Creating model\n2020-02-28 23:38:22.059994 Compiling model\n2020-02-28 23:38:22.115804 Fitting model\nEpoch 1/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.5988 - accuracy: 0.6898\nEpoch 2/5\n7798/7798 [==============================] - 9s 1ms/step - loss: 0.2567 - accuracy: 0.9066\nEpoch 3/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0824 - accuracy: 0.9792\nEpoch 4/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0256 - accuracy: 0.9967\nEpoch 5/5\n7798/7798 [==============================] - 8s 1ms/step - loss: 0.0097 - accuracy: 0.9994\n2020-02-28 23:39:07.433404 Evaluating model\n866/866 [==============================] - 1s 765us/step\n2020-02-28 23:39:08.702015 Done evaluating, accuracy=0.7621247172355652\n"
    }
   ],
   "source": [
    "# Q3.1 do the 10-fold cross validation and store the results for each model\n",
    "# and store the results in 'q3_1_results'\n",
    "q3_1_results = []\n",
    "for model_num in range(len(nodes)):\n",
    "    q3_1_results.append([])\n",
    "    for i in range(10):\n",
    "        training_x = []; training_y = []\n",
    "        test_x = []; test_y = []\n",
    "        log(\"Splitting test-training data (sentence #{} to test set)\".format(i+1))\n",
    "        for j in range(len(hot_ones)):\n",
    "            if i == (j % 10):\n",
    "                # add when the counter values coincide, add the hot-ones for this sentence to the test set\n",
    "                test_x.append(np.array(hot_ones[j])); test_y.append(Y[j])\n",
    "            else:\n",
    "                # add the hot-ones for this sentence to the training set\n",
    "                training_x.append(np.array(hot_ones[j])); training_y.append(Y[j])\n",
    "\n",
    "        log(\"Creating model\"); q3_1_model = make_model(nodes[model_num], len(full_vocab))\n",
    "\n",
    "        log(\"Compiling model\"); q3_1_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        log(\"Fitting model\"); q3_1_model.fit(np.array(training_x), np.array(training_y), epochs=5, batch_size=128)\n",
    "\n",
    "        log(\"Evaluating model\"); _, accuracy = q3_1_model.evaluate(np.array(test_x), np.array(test_y))\n",
    "        q3_1_results[model_num].append(accuracy)\n",
    "\n",
    "        log(\"Done evaluating, accuracy={}\".format(q3_1_results[model_num][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.7739331126213074, 0.7301037907600403, 0.7647058963775635, 0.7474048733711243, 0.7667436599731445, 0.7609699964523315, 0.7528868317604065, 0.7378752827644348, 0.7632794380187988, 0.7621247172355652]\naverage for 100 nodes in 1st hidden layer: 0.7560027599334717\n[0.7670127153396606, 0.7370242476463318, 0.7635524868965149, 0.7404844164848328, 0.7598152160644531, 0.7644341588020325, 0.7528868317604065, 0.7459584474563599, 0.7575057744979858, 0.7575057744979858]\naverage for 200 nodes in 1st hidden layer: 0.7546180069446564\n[0.769319474697113, 0.7370242476463318, 0.7670127153396606, 0.7381775975227356, 0.7575057744979858, 0.7702078819274902, 0.7621247172355652, 0.7551963329315186, 0.7563510537147522, 0.7621247172355652]\naverage for 300 nodes in 1st hidden layer: 0.7575044512748719\n"
    }
   ],
   "source": [
    "# write the results to the answer file\n",
    "q3_1_results_file = open(\"Q3_1_Results.txt\", \"w\")\n",
    "q3_1_results_file.write(\"1.\\tParameter chosen for optimizations was the number of nodes in hidden layer 1\\n\")\n",
    "q3_1_results_file.write(\"2.\\tnode counts: {}\\n\".format(nodes))\n",
    "q3_1_results_avg = [np.average(q3_1_results[i]) for i in range(len(q3_1_results))]\n",
    "max_node_count = nodes[list(q3_1_results_avg).index(np.max(q3_1_results_avg))]\n",
    "for i in range(3):\n",
    "    print(str(q3_1_results[i]))\n",
    "    print(\"average for {} nodes in 1st hidden layer: {}\".format(nodes[i], q3_1_results_avg[i]))\n",
    "q3_1_results_file.write(\"3.\\tAccuracy for Node Count:\\n\" +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[0], q3_1_results_avg[0]) +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[1], q3_1_results_avg[1]) +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[2], q3_1_results_avg[2]))\n",
    "q3_1_results_file.write(\"4.\\tChosen node count is {} because it had the highest average accuracy in the 10-fold cross validation.\\n\".format(max_node_count))\n",
    "q3_1_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-28 23:39:08.737921 Creating model\n2020-02-28 23:39:08.817706 Compiling model\n2020-02-28 23:39:08.899490 Fitting model\nEpoch 1/5\n8664/8664 [==============================] - 10s 1ms/step - loss: 0.6017 - accuracy: 0.6924\nEpoch 2/5\n8664/8664 [==============================] - 9s 1ms/step - loss: 0.2808 - accuracy: 0.8937\nEpoch 3/5\n8664/8664 [==============================] - 9s 1ms/step - loss: 0.0938 - accuracy: 0.9733\nEpoch 4/5\n8664/8664 [==============================] - 9s 1ms/step - loss: 0.0341 - accuracy: 0.9920\nEpoch 5/5\n8664/8664 [==============================] - 9s 1ms/step - loss: 0.0130 - accuracy: 0.9984\n2020-02-28 23:39:58.416498 Evaluating model\n8664/8664 [==============================] - 4s 453us/step\n2020-02-28 23:40:03.229133 Done evaluating, accuracy=0.9998846054077148\n"
    }
   ],
   "source": [
    "# Q3.2 retrain the model on the entire training set and report the accuracy on the training set as an upper-bound for performance on test data\n",
    "\n",
    "log(\"Creating model\"); q3_2_model = make_model(max_node_count, len(full_vocab))\n",
    "\n",
    "log(\"Compiling model\"); q3_2_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "log(\"Fitting model\"); q3_2_model.fit(np.array(hot_ones), np.array(Y), epochs=5, batch_size=128)\n",
    "\n",
    "log(\"Evaluating model\"); q3_2_loss, q3_2_accuracy = q3_2_model.evaluate(np.array(hot_ones), np.array(Y))\n",
    "\n",
    "log(\"Done evaluating, accuracy={}\".format(q3_2_accuracy))\n",
    "\n",
    "q3_2_results_file = open(\"Q3_2_Results.txt\", \"w\")\n",
    "q3_2_results_file.write(\"Trainied model on full data with {} nodes\\n\".format(max_node_count))\n",
    "q3_2_results_file.write(\"\\taccuracy = {} ; loss = {}\\n\".format(q3_2_accuracy, q3_2_loss))\n",
    "q3_2_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-28 23:40:03.878348 generating vord2vec model\n2020-02-28 23:42:42.987589 generated\n"
    }
   ],
   "source": [
    "import gensim.models as gm\n",
    "log(\"generating vord2vec model\")\n",
    "google_kv = gm.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "log(\"generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that finds the average word vector for a sentence\n",
    "def get_sentence_vector(sentence):\n",
    "    vectors = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vectors.append(google_kv.get_vector(word))\n",
    "        except KeyError:\n",
    "            vectors.append([0] * 300)\n",
    "    vectors_ave = np.mean(vectors, axis=0)\n",
    "    return vectors_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-28 23:42:43.014527 building word2vec array\n2020-02-28 23:42:45.319394 word2vec done\n"
    }
   ],
   "source": [
    "# read the positive and negative reviews into wprd2vec encodings\n",
    "log('building word2vec array')\n",
    "word2vec = []\n",
    "i = 0\n",
    "for sentence in full_data:\n",
    "    sentence_vec = get_sentence_vector(sentence)\n",
    "    if np.isnan(sentence_vec).any():\n",
    "        sentence_vec = np.zeros(300)\n",
    "    word2vec.append(sentence_vec)\n",
    "    i += 1\n",
    "log(\"word2vec done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "=======================] - 1s 65us/step - loss: 0.4350 - accuracy: 0.7969\nEpoch 9/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.4263 - accuracy: 0.8005\nEpoch 10/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.4216 - accuracy: 0.8017\nEpoch 11/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4129 - accuracy: 0.8083\nEpoch 12/30\n7798/7798 [==============================] - 0s 63us/step - loss: 0.4052 - accuracy: 0.8125\nEpoch 13/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3966 - accuracy: 0.8150\nEpoch 14/30\n7798/7798 [==============================] - 1s 64us/step - loss: 0.3866 - accuracy: 0.8237\nEpoch 15/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.3772 - accuracy: 0.8287\nEpoch 16/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3642 - accuracy: 0.8360\nEpoch 17/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3478 - accuracy: 0.8475\nEpoch 18/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.3367 - accuracy: 0.8518\nEpoch 19/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3229 - accuracy: 0.8621\nEpoch 20/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3113 - accuracy: 0.8714\nEpoch 21/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2928 - accuracy: 0.8804\nEpoch 22/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2751 - accuracy: 0.8910\nEpoch 23/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2685 - accuracy: 0.8933\nEpoch 24/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2531 - accuracy: 0.9011\nEpoch 25/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.2443 - accuracy: 0.9048\nEpoch 26/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2268 - accuracy: 0.9183\nEpoch 27/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2124 - accuracy: 0.9254\nEpoch 28/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2059 - accuracy: 0.9272\nEpoch 29/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.1863 - accuracy: 0.9395\nEpoch 30/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.1734 - accuracy: 0.9445\n2020-02-28 23:49:43.736072 Evaluating model\n866/866 [==============================] - 1s 640us/step\n2020-02-28 23:49:45.218277 Done evaluating, accuracy=0.7655889391899109\n2020-02-28 23:49:45.221269 Splitting test-training data (sentence #6 to test set)\n2020-02-28 23:49:45.238223 Creating model\n2020-02-28 23:49:45.289088 Compiling model\n2020-02-28 23:49:45.348927 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 146us/step - loss: 0.6050 - accuracy: 0.7030\nEpoch 2/30\n7798/7798 [==============================] - 0s 63us/step - loss: 0.4941 - accuracy: 0.7655\nEpoch 3/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4710 - accuracy: 0.7729\nEpoch 4/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4594 - accuracy: 0.7824\nEpoch 5/30\n7798/7798 [==============================] - 1s 64us/step - loss: 0.4525 - accuracy: 0.7848\nEpoch 6/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4490 - accuracy: 0.7835\nEpoch 7/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.4429 - accuracy: 0.7921\nEpoch 8/30\n7798/7798 [==============================] - 0s 64us/step - loss: 0.4369 - accuracy: 0.7952\nEpoch 9/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.4355 - accuracy: 0.7925\nEpoch 10/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4250 - accuracy: 0.8016\nEpoch 11/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.4164 - accuracy: 0.8037\nEpoch 12/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.4061 - accuracy: 0.8116\nEpoch 13/30\n7798/7798 [==============================] - 1s 64us/step - loss: 0.4025 - accuracy: 0.8116\nEpoch 14/30\n7798/7798 [==============================] - 0s 61us/step - loss: 0.3881 - accuracy: 0.8224\nEpoch 15/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3772 - accuracy: 0.8289\nEpoch 16/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3703 - accuracy: 0.8344\nEpoch 17/30\n7798/7798 [==============================] - 1s 64us/step - loss: 0.3555 - accuracy: 0.8414\nEpoch 18/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.3432 - accuracy: 0.8512\nEpoch 19/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3329 - accuracy: 0.8577\nEpoch 20/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3177 - accuracy: 0.8674\nEpoch 21/30\n7798/7798 [==============================] - 0s 64us/step - loss: 0.3098 - accuracy: 0.8682\nEpoch 22/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2919 - accuracy: 0.8823\nEpoch 23/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.2781 - accuracy: 0.8877\nEpoch 24/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2653 - accuracy: 0.8970\nEpoch 25/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2523 - accuracy: 0.9036\nEpoch 26/30\n7798/7798 [==============================] - 0s 63us/step - loss: 0.2389 - accuracy: 0.9128\nEpoch 27/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.2260 - accuracy: 0.9163\nEpoch 28/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2195 - accuracy: 0.9191\nEpoch 29/30\n7798/7798 [==============================] - 0s 64us/step - loss: 0.1988 - accuracy: 0.9331\nEpoch 30/30\n7798/7798 [==============================] - 0s 64us/step - loss: 0.1877 - accuracy: 0.9377\n2020-02-28 23:50:05.764416 Evaluating model\n866/866 [==============================] - 1s 652us/step\n2020-02-28 23:50:07.291785 Done evaluating, accuracy=0.7782909870147705\n2020-02-28 23:50:07.296819 Splitting test-training data (sentence #7 to test set)\n2020-02-28 23:50:07.313759 Creating model\n2020-02-28 23:50:07.362629 Compiling model\n2020-02-28 23:50:07.421226 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 145us/step - loss: 0.5919 - accuracy: 0.7076\nEpoch 2/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4774 - accuracy: 0.7711\nEpoch 3/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4580 - accuracy: 0.7814\nEpoch 4/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.4535 - accuracy: 0.7829\nEpoch 5/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4418 - accuracy: 0.7911\nEpoch 6/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4338 - accuracy: 0.7942\nEpoch 7/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4329 - accuracy: 0.7974\nEpoch 8/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4204 - accuracy: 0.8023\nEpoch 9/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4137 - accuracy: 0.8070\nEpoch 10/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4078 - accuracy: 0.8115\nEpoch 11/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3953 - accuracy: 0.8182\nEpoch 12/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3894 - accuracy: 0.8217\nEpoch 13/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3712 - accuracy: 0.8319\nEpoch 14/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3576 - accuracy: 0.8451\nEpoch 15/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3477 - accuracy: 0.8503\nEpoch 16/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3324 - accuracy: 0.8564\nEpoch 17/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3160 - accuracy: 0.8656\nEpoch 18/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3025 - accuracy: 0.8723\nEpoch 19/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3009 - accuracy: 0.8752\nEpoch 20/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.2805 - accuracy: 0.8900\nEpoch 21/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.2615 - accuracy: 0.8960\nEpoch 22/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2435 - accuracy: 0.9064\nEpoch 23/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2276 - accuracy: 0.9160\nEpoch 24/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.2135 - accuracy: 0.9228\nEpoch 25/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2076 - accuracy: 0.9251\nEpoch 26/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.1858 - accuracy: 0.9373\nEpoch 27/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.1789 - accuracy: 0.9424\nEpoch 28/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.1578 - accuracy: 0.9540\nEpoch 29/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.1495 - accuracy: 0.9559\nEpoch 30/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.1350 - accuracy: 0.9631\n2020-02-28 23:50:28.884296 Evaluating model\n866/866 [==============================] - 1s 645us/step\n2020-02-28 23:50:30.417662 Done evaluating, accuracy=0.7482678890228271\n2020-02-28 23:50:30.421698 Splitting test-training data (sentence #8 to test set)\n2020-02-28 23:50:30.437608 Creating model\n2020-02-28 23:50:30.484515 Compiling model\n2020-02-28 23:50:30.542363 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.6140 - accuracy: 0.6868\nEpoch 2/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4927 - accuracy: 0.7646\nEpoch 3/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.4672 - accuracy: 0.7762\nEpoch 4/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4577 - accuracy: 0.7808\nEpoch 5/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4534 - accuracy: 0.7837\nEpoch 6/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4514 - accuracy: 0.7825\nEpoch 7/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4433 - accuracy: 0.7898\nEpoch 8/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4366 - accuracy: 0.7917\nEpoch 9/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4321 - accuracy: 0.7952\nEpoch 10/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4257 - accuracy: 0.7983\nEpoch 11/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4197 - accuracy: 0.8007\nEpoch 12/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4171 - accuracy: 0.8001\nEpoch 13/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4113 - accuracy: 0.8033\nEpoch 14/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.3976 - accuracy: 0.8135\nEpoch 15/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.3862 - accuracy: 0.8209\nEpoch 16/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.3812 - accuracy: 0.8233\nEpoch 17/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.3743 - accuracy: 0.8305\nEpoch 18/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3620 - accuracy: 0.8301\nEpoch 19/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3505 - accuracy: 0.8368\nEpoch 20/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3404 - accuracy: 0.8482\nEpoch 21/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.3254 - accuracy: 0.8577\nEpoch 22/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3161 - accuracy: 0.8630\nEpoch 23/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3020 - accuracy: 0.8691\nEpoch 24/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2889 - accuracy: 0.8766\nEpoch 25/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2824 - accuracy: 0.8837\nEpoch 26/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2661 - accuracy: 0.8928\nEpoch 27/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2560 - accuracy: 0.8970\nEpoch 28/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.2423 - accuracy: 0.9072\nEpoch 29/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2313 - accuracy: 0.9128\nEpoch 30/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2231 - accuracy: 0.9127\n2020-02-28 23:50:51.672930 Evaluating model\n866/866 [==============================] - 1s 650us/step\n2020-02-28 23:50:53.254465 Done evaluating, accuracy=0.7725173234939575\n2020-02-28 23:50:53.258455 Splitting test-training data (sentence #9 to test set)\n2020-02-28 23:50:53.274411 Creating model\n2020-02-28 23:50:53.331261 Compiling model\n2020-02-28 23:50:53.389104 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 148us/step - loss: 0.6076 - accuracy: 0.7077\nEpoch 2/30\n7798/7798 [==============================] - 1s 65us/step - loss: 0.4896 - accuracy: 0.7616\nEpoch 3/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4672 - accuracy: 0.7775\nEpoch 4/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4608 - accuracy: 0.7810\nEpoch 5/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4519 - accuracy: 0.7866\nEpoch 6/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4491 - accuracy: 0.7855\nEpoch 7/30\n7798/7798 [==============================] - 1s 64us/step - loss: 0.4472 - accuracy: 0.7870\nEpoch 8/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.4377 - accuracy: 0.7932\nEpoch 9/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.4298 - accuracy: 0.7955\nEpoch 10/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4293 - accuracy: 0.7989\nEpoch 11/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4186 - accuracy: 0.8025\nEpoch 12/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.4074 - accuracy: 0.8088\nEpoch 13/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3982 - accuracy: 0.8166\nEpoch 14/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3866 - accuracy: 0.8244\nEpoch 15/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3772 - accuracy: 0.8309\nEpoch 16/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3663 - accuracy: 0.8370\nEpoch 17/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3522 - accuracy: 0.8441\nEpoch 18/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3392 - accuracy: 0.8536\nEpoch 19/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3260 - accuracy: 0.8601\nEpoch 20/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.3093 - accuracy: 0.8734\nEpoch 21/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2969 - accuracy: 0.8811\nEpoch 22/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2841 - accuracy: 0.8815\nEpoch 23/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.2657 - accuracy: 0.8956\nEpoch 24/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2538 - accuracy: 0.9022\nEpoch 25/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2380 - accuracy: 0.9098\nEpoch 26/30\n7798/7798 [==============================] - 1s 66us/step - loss: 0.2234 - accuracy: 0.9163\nEpoch 27/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.2100 - accuracy: 0.9241\nEpoch 28/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.1992 - accuracy: 0.9318\nEpoch 29/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.1848 - accuracy: 0.9378\nEpoch 30/30\n7798/7798 [==============================] - 1s 68us/step - loss: 0.1690 - accuracy: 0.9458\n2020-02-28 23:51:14.742128 Evaluating model\n866/866 [==============================] - 1s 673us/step\n2020-02-28 23:51:16.332993 Done evaluating, accuracy=0.7921478152275085\n2020-02-28 23:51:16.338008 Splitting test-training data (sentence #10 to test set)\n2020-02-28 23:51:16.354929 Creating model\n2020-02-28 23:51:16.401806 Compiling model\n2020-02-28 23:51:16.461677 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 149us/step - loss: 0.6162 - accuracy: 0.6634\nEpoch 2/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.4895 - accuracy: 0.7660\nEpoch 3/30\n7798/7798 [==============================] - 1s 67us/step - loss: 0.4647 - accuracy: 0.7784\nEpoch 4/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4569 - accuracy: 0.7830\nEpoch 5/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4526 - accuracy: 0.7810\nEpoch 6/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4443 - accuracy: 0.7901\nEpoch 7/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4383 - accuracy: 0.7989\nEpoch 8/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4302 - accuracy: 0.7994\nEpoch 9/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4236 - accuracy: 0.8060\nEpoch 10/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.4163 - accuracy: 0.8056\nEpoch 11/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.4091 - accuracy: 0.8116\nEpoch 12/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.3983 - accuracy: 0.8160\nEpoch 13/30\n7798/7798 [==============================] - 1s 69us/step - loss: 0.3880 - accuracy: 0.8264\nEpoch 14/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.3796 - accuracy: 0.8270\nEpoch 15/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.3654 - accuracy: 0.8382\nEpoch 16/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.3544 - accuracy: 0.8453\nEpoch 17/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.3460 - accuracy: 0.8493\nEpoch 18/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.3306 - accuracy: 0.8588\nEpoch 19/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.3169 - accuracy: 0.8647\nEpoch 20/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.3035 - accuracy: 0.8756\nEpoch 21/30\n7798/7798 [==============================] - 1s 71us/step - loss: 0.2896 - accuracy: 0.8841\nEpoch 22/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.2779 - accuracy: 0.8897\nEpoch 23/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2663 - accuracy: 0.8996\nEpoch 24/30\n7798/7798 [==============================] - 1s 72us/step - loss: 0.2476 - accuracy: 0.9083\nEpoch 25/30\n7798/7798 [==============================] - 1s 74us/step - loss: 0.2387 - accuracy: 0.9142\nEpoch 26/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.2227 - accuracy: 0.9206\nEpoch 27/30\n7798/7798 [==============================] - 1s 70us/step - loss: 0.2146 - accuracy: 0.9240\nEpoch 28/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.2055 - accuracy: 0.9292\nEpoch 29/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.1862 - accuracy: 0.9368\nEpoch 30/30\n7798/7798 [==============================] - 1s 73us/step - loss: 0.1738 - accuracy: 0.9456\n2020-02-28 23:51:38.691187 Evaluating model\n866/866 [==============================] - 1s 698us/step\n2020-02-28 23:51:40.339241 Done evaluating, accuracy=0.7736720442771912\n"
    }
   ],
   "source": [
    "# Q3.3 do the 10-fold cross validation and store the results for each model\n",
    "# and store the results in 'q3_3_results'\n",
    "q3_3_results = []\n",
    "for model_num in range(len(nodes)):\n",
    "    q3_3_results.append([])\n",
    "    for i in range(10):\n",
    "        training_x = []; training_y = []\n",
    "        test_x = []; test_y = []\n",
    "        log(\"Splitting test-training data (sentence #{} to test set)\".format(i+1))\n",
    "        for j in range(len(word2vec)):\n",
    "            if i == (j % 10):\n",
    "                # add when the counter values coincide, add the hot-ones for this sentence to the test set\n",
    "                test_x.append(np.array(word2vec[j])); test_y.append(Y[j])\n",
    "            else:\n",
    "                # add the hot-ones for this sentence to the training set\n",
    "                training_x.append(np.array(word2vec[j])); training_y.append(Y[j])\n",
    "\n",
    "        log(\"Creating model\"); q3_3_model = make_model(nodes[model_num], 300)\n",
    "\n",
    "        log(\"Compiling model\"); q3_3_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        log(\"Fitting model\"); q3_3_model.fit(np.array(training_x), np.array(training_y), epochs=30, batch_size=128)\n",
    "\n",
    "        log(\"Evaluating model\"); _, accuracy = q3_3_model.evaluate(np.array(test_x), np.array(test_y))\n",
    "        q3_3_results[model_num].append(accuracy)\n",
    "\n",
    "        log(\"Done evaluating, accuracy={}\".format(q3_3_results[model_num][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.7623990774154663, 0.7589388489723206, 0.7658593058586121, 0.7681660652160645, 0.7621247172355652, 0.7909930944442749, 0.7436489462852478, 0.7956120371818542, 0.8002309203147888, 0.7886835932731628]\naverage for 100 nodes in 1st hidden layer: 0.7736656606197357\n[0.754325270652771, 0.7531718611717224, 0.7739331126213074, 0.7658593058586121, 0.7632794380187988, 0.7806004881858826, 0.7436489462852478, 0.7621247172355652, 0.8025404214859009, 0.7678983807563782]\naverage for 200 nodes in 1st hidden layer: 0.7667381942272187\n[0.7520184516906738, 0.7497116327285767, 0.769319474697113, 0.7658593058586121, 0.7655889391899109, 0.7782909870147705, 0.7482678890228271, 0.7725173234939575, 0.7921478152275085, 0.7736720442771912]\naverage for 300 nodes in 1st hidden layer: 0.7667393863201142\n2020-02-28 23:51:40.358188 Creating model\n2020-02-28 23:51:40.419026 Compiling model\n2020-02-28 23:51:40.484852 Fitting model\nEpoch 1/30\n8664/8664 [==============================] - 1s 130us/step - loss: 0.6374 - accuracy: 0.6790\nEpoch 2/30\n8664/8664 [==============================] - 0s 56us/step - loss: 0.5110 - accuracy: 0.7574\nEpoch 3/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.4730 - accuracy: 0.7722\nEpoch 4/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.4616 - accuracy: 0.7817\nEpoch 5/30\n8664/8664 [==============================] - 0s 57us/step - loss: 0.4552 - accuracy: 0.7817\nEpoch 6/30\n8664/8664 [==============================] - 1s 64us/step - loss: 0.4522 - accuracy: 0.7857\nEpoch 7/30\n8664/8664 [==============================] - 1s 63us/step - loss: 0.4468 - accuracy: 0.7907\nEpoch 8/30\n8664/8664 [==============================] - 1s 61us/step - loss: 0.4457 - accuracy: 0.7901\nEpoch 9/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.4407 - accuracy: 0.7911\nEpoch 10/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.4361 - accuracy: 0.7919\nEpoch 11/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.4310 - accuracy: 0.7976\nEpoch 12/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.4282 - accuracy: 0.7996\nEpoch 13/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.4241 - accuracy: 0.8037\nEpoch 14/30\n8664/8664 [==============================] - 1s 60us/step - loss: 0.4189 - accuracy: 0.8039\nEpoch 15/30\n8664/8664 [==============================] - 1s 60us/step - loss: 0.4108 - accuracy: 0.8076\nEpoch 16/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.4046 - accuracy: 0.8119\nEpoch 17/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3989 - accuracy: 0.8151\nEpoch 18/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3943 - accuracy: 0.8168\nEpoch 19/30\n8664/8664 [==============================] - 0s 57us/step - loss: 0.3863 - accuracy: 0.8232\nEpoch 20/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3779 - accuracy: 0.8280\nEpoch 21/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3729 - accuracy: 0.8301\nEpoch 22/30\n8664/8664 [==============================] - 0s 57us/step - loss: 0.3660 - accuracy: 0.8339\nEpoch 23/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.3602 - accuracy: 0.8400\nEpoch 24/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3514 - accuracy: 0.8391\nEpoch 25/30\n8664/8664 [==============================] - 1s 61us/step - loss: 0.3418 - accuracy: 0.8478\nEpoch 26/30\n8664/8664 [==============================] - 1s 59us/step - loss: 0.3330 - accuracy: 0.8524\nEpoch 27/30\n8664/8664 [==============================] - 0s 58us/step - loss: 0.3307 - accuracy: 0.8561\nEpoch 28/30\n8664/8664 [==============================] - 1s 60us/step - loss: 0.3182 - accuracy: 0.8609\nEpoch 29/30\n8664/8664 [==============================] - 1s 58us/step - loss: 0.3096 - accuracy: 0.8678\nEpoch 30/30\n8664/8664 [==============================] - 1s 60us/step - loss: 0.3098 - accuracy: 0.8651\n2020-02-28 23:52:01.199320 Evaluating model\n8664/8664 [==============================] - 1s 143us/step\n2020-02-28 23:52:03.464502 Done evaluating, accuracy=0.8561865091323853\n"
    }
   ],
   "source": [
    "# write the results to the answer file\n",
    "q3_3_results_file = open(\"Q3_3_Results.txt\", \"w\")\n",
    "q3_3_results_file.write(\"1.\\tParameter chosen for optimizations was the number of nodes in hidden layer 1\\n\")\n",
    "q3_3_results_file.write(\"2.\\tnode counts: {}\\n\".format(nodes))\n",
    "q3_3_results_avg = [np.average(q3_3_results[i]) for i in range(len(q3_3_results))]\n",
    "max_node_count = nodes[list(q3_3_results_avg).index(np.max(q3_3_results_avg))]\n",
    "for i in range(3):\n",
    "    print(str(q3_3_results[i]))\n",
    "    print(\"average for {} nodes in 1st hidden layer: {}\".format(nodes[i], q3_3_results_avg[i]))\n",
    "q3_3_results_file.write(\"3.\\tAccuracy for Node Count:\\n\" +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[0], q3_3_results_avg[0]) +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[1], q3_3_results_avg[1]) +\\\n",
    "                        \"\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[2], q3_3_results_avg[2]))\n",
    "q3_3_results_file.write(\"4.\\tChosen node count is {} because it had the highest average accuracy in the 10-fold cross validation.\\n\".format(max_node_count))\n",
    "\n",
    "# retrain the model on the entire training set and report the accuracy on the training set as an upper-bound for performance on test data\n",
    "\n",
    "log(\"Creating model\"); q3_3_model = make_model(max_node_count, 300)\n",
    "\n",
    "log(\"Compiling model\"); q3_3_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "log(\"Fitting model\"); q3_3_model.fit(np.array(word2vec), np.array(Y), epochs=30, batch_size=128)\n",
    "\n",
    "log(\"Evaluating model\"); q3_3_loss, q3_3_accuracy = q3_3_model.evaluate(np.array(word2vec), np.array(Y))\n",
    "\n",
    "log(\"Done evaluating, accuracy={}\".format(q3_3_accuracy))\n",
    "\n",
    "q3_3_results_file.write(\"5.\\tTrainied model on full data with {} nodes\\n\".format(max_node_count))\n",
    "q3_3_results_file.write(\"\\t\\taccuracy = {} ; loss = {}\\n\".format(q3_3_accuracy, q3_3_loss))\n",
    "q3_3_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-28 23:52:03.923518 created sentence list from files\n"
    }
   ],
   "source": [
    "# read the training doccuments in to a list of sentences\n",
    "pos_file = open('train_positive_reviews.txt', \"rt\")\n",
    "neg_file = open('train_negative_reviews.txt', \"rt\")\n",
    "full_sents = [sentence.strip() for sentence in pos_file.readlines() + neg_file.readlines()]\n",
    "log(\"created sentence list from files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8664, 16675)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the tfidf vectorizer over the sentences\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "full_tfidf = tfidf_vectorizer.fit_transform(full_sents)\n",
    "full_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters to optimize the SVD and neural net over:\n",
    "nodes = [100, 200, 300]\n",
    "component_counts = [200, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "===========================] - 1s 85us/step - loss: 0.4425 - accuracy: 0.7932\nEpoch 9/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.4269 - accuracy: 0.8015\nEpoch 10/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.4098 - accuracy: 0.8167\nEpoch 11/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.3884 - accuracy: 0.8309\nEpoch 12/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.3665 - accuracy: 0.8456\nEpoch 13/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.3408 - accuracy: 0.8671\nEpoch 14/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.3146 - accuracy: 0.8823\nEpoch 15/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.2865 - accuracy: 0.8988\nEpoch 16/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.2588 - accuracy: 0.9173\nEpoch 17/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.2324 - accuracy: 0.9327\nEpoch 18/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.2058 - accuracy: 0.9451\nEpoch 19/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.1824 - accuracy: 0.9536\nEpoch 20/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.1614 - accuracy: 0.9604\nEpoch 21/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.1396 - accuracy: 0.9704\nEpoch 22/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.1229 - accuracy: 0.9763\nEpoch 23/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.1065 - accuracy: 0.9805\nEpoch 24/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.0919 - accuracy: 0.9837\nEpoch 25/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.0810 - accuracy: 0.9873\nEpoch 26/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.0694 - accuracy: 0.9899\nEpoch 27/30\n7798/7798 [==============================] - 1s 99us/step - loss: 0.0610 - accuracy: 0.9927\nEpoch 28/30\n7798/7798 [==============================] - 1s 111us/step - loss: 0.0540 - accuracy: 0.9935\nEpoch 29/30\n7798/7798 [==============================] - 1s 106us/step - loss: 0.0483 - accuracy: 0.9944\nEpoch 30/30\n7798/7798 [==============================] - 1s 92us/step - loss: 0.0417 - accuracy: 0.9946\n2020-02-29 00:04:19.976032 Evaluating model\n866/866 [==============================] - 1s 1ms/step\n2020-02-29 00:04:22.449480 Done evaluating, accuracy=0.7424942255020142\n2020-02-29 00:04:27.166863 Splitting test-training data (sentence #6 to test set)\n2020-02-29 00:04:27.192825 Creating model\n2020-02-29 00:04:27.277565 Compiling model\n2020-02-29 00:04:27.358382 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 2s 205us/step - loss: 0.6844 - accuracy: 0.5867\nEpoch 2/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.6204 - accuracy: 0.7292\nEpoch 3/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.5299 - accuracy: 0.7499\nEpoch 4/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.4956 - accuracy: 0.7585\nEpoch 5/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.4829 - accuracy: 0.7655\nEpoch 6/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.4732 - accuracy: 0.7739\nEpoch 7/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.4659 - accuracy: 0.7765\nEpoch 8/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4561 - accuracy: 0.7803\nEpoch 9/30\n7798/7798 [==============================] - 1s 89us/step - loss: 0.4478 - accuracy: 0.7857\nEpoch 10/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4360 - accuracy: 0.7906\nEpoch 11/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4245 - accuracy: 0.8001\nEpoch 12/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4090 - accuracy: 0.8125\nEpoch 13/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.3946 - accuracy: 0.8226\nEpoch 14/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.3788 - accuracy: 0.8305\nEpoch 15/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.3593 - accuracy: 0.8425\nEpoch 16/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.3390 - accuracy: 0.8582\nEpoch 17/30\n7798/7798 [==============================] - 1s 89us/step - loss: 0.3150 - accuracy: 0.8763\nEpoch 18/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.2920 - accuracy: 0.8883\nEpoch 19/30\n7798/7798 [==============================] - 1s 88us/step - loss: 0.2677 - accuracy: 0.9033\nEpoch 20/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.2425 - accuracy: 0.9219\nEpoch 21/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.2201 - accuracy: 0.9358\nEpoch 22/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.1965 - accuracy: 0.9441\nEpoch 23/30\n7798/7798 [==============================] - 1s 88us/step - loss: 0.1745 - accuracy: 0.9542\nEpoch 24/30\n7798/7798 [==============================] - 1s 87us/step - loss: 0.1534 - accuracy: 0.9664\nEpoch 25/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.1367 - accuracy: 0.9706\nEpoch 26/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.1208 - accuracy: 0.9770\nEpoch 27/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.1062 - accuracy: 0.9806\nEpoch 28/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.0930 - accuracy: 0.9850\nEpoch 29/30\n7798/7798 [==============================] - 1s 89us/step - loss: 0.0818 - accuracy: 0.9886\nEpoch 30/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.0726 - accuracy: 0.9900\n2020-02-29 00:04:56.009569 Evaluating model\n866/866 [==============================] - 1s 1ms/step\n2020-02-29 00:04:58.483273 Done evaluating, accuracy=0.7205542922019958\n2020-02-29 00:05:03.052571 Splitting test-training data (sentence #7 to test set)\n2020-02-29 00:05:03.081494 Creating model\n2020-02-29 00:05:03.149312 Compiling model\n2020-02-29 00:05:03.227110 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 188us/step - loss: 0.6855 - accuracy: 0.6008\nEpoch 2/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.6188 - accuracy: 0.7202\nEpoch 3/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.5209 - accuracy: 0.7537\nEpoch 4/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.4863 - accuracy: 0.7631\nEpoch 5/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.4746 - accuracy: 0.7680\nEpoch 6/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.4625 - accuracy: 0.7751\nEpoch 7/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.4523 - accuracy: 0.7823\nEpoch 8/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.4398 - accuracy: 0.7921\nEpoch 9/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.4254 - accuracy: 0.8010\nEpoch 10/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.4084 - accuracy: 0.8092\nEpoch 11/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.3923 - accuracy: 0.8214\nEpoch 12/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.3716 - accuracy: 0.8366\nEpoch 13/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.3480 - accuracy: 0.8529\nEpoch 14/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.3241 - accuracy: 0.8711\nEpoch 15/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.2989 - accuracy: 0.8845\nEpoch 16/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.2722 - accuracy: 0.9023\nEpoch 17/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.2458 - accuracy: 0.9157\nEpoch 18/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.2208 - accuracy: 0.9293\nEpoch 19/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.1966 - accuracy: 0.9443\nEpoch 20/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.1728 - accuracy: 0.9568\nEpoch 21/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.1530 - accuracy: 0.9627\nEpoch 22/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.1356 - accuracy: 0.9678\nEpoch 23/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.1207 - accuracy: 0.9754\nEpoch 24/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.1044 - accuracy: 0.9803\nEpoch 25/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.0909 - accuracy: 0.9853\nEpoch 26/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.0797 - accuracy: 0.9874\nEpoch 27/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.0695 - accuracy: 0.9908\nEpoch 28/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.0617 - accuracy: 0.9917\nEpoch 29/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0541 - accuracy: 0.9935\nEpoch 30/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0474 - accuracy: 0.9941\n2020-02-29 00:05:29.837137 Evaluating model\n866/866 [==============================] - 1s 971us/step\n2020-02-29 00:05:32.189515 Done evaluating, accuracy=0.7251732349395752\n2020-02-29 00:05:36.587603 Splitting test-training data (sentence #8 to test set)\n2020-02-29 00:05:36.618520 Creating model\n2020-02-29 00:05:36.690334 Compiling model\n2020-02-29 00:05:36.767088 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 186us/step - loss: 0.6858 - accuracy: 0.5533\nEpoch 2/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.6279 - accuracy: 0.7034\nEpoch 3/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.5327 - accuracy: 0.7506\nEpoch 4/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.4923 - accuracy: 0.7620\nEpoch 5/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.4753 - accuracy: 0.7698\nEpoch 6/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.4618 - accuracy: 0.7802\nEpoch 7/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.4522 - accuracy: 0.7879\nEpoch 8/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4371 - accuracy: 0.7937\nEpoch 9/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.4228 - accuracy: 0.8055\nEpoch 10/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.4063 - accuracy: 0.8164\nEpoch 11/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.3859 - accuracy: 0.8291\nEpoch 12/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.3675 - accuracy: 0.8433\nEpoch 13/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.3426 - accuracy: 0.8596\nEpoch 14/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.3176 - accuracy: 0.8783\nEpoch 15/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.2913 - accuracy: 0.8946\nEpoch 16/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.2661 - accuracy: 0.9075\nEpoch 17/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.2409 - accuracy: 0.9209\nEpoch 18/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.2151 - accuracy: 0.9365\nEpoch 19/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.1913 - accuracy: 0.9487\nEpoch 20/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.1690 - accuracy: 0.9586\nEpoch 21/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.1490 - accuracy: 0.9669\nEpoch 22/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.1326 - accuracy: 0.9722\nEpoch 23/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.1176 - accuracy: 0.9782\nEpoch 24/30\n7798/7798 [==============================] - 1s 76us/step - loss: 0.1026 - accuracy: 0.9832\nEpoch 25/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.0900 - accuracy: 0.9859\nEpoch 26/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.0792 - accuracy: 0.9885\nEpoch 27/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.0693 - accuracy: 0.9904\nEpoch 28/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.0616 - accuracy: 0.9926\nEpoch 29/30\n7798/7798 [==============================] - 1s 77us/step - loss: 0.0546 - accuracy: 0.9929\nEpoch 30/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.0485 - accuracy: 0.9944\n2020-02-29 00:06:02.922384 Evaluating model\n866/866 [==============================] - 1s 996us/step\n2020-02-29 00:06:05.291555 Done evaluating, accuracy=0.6997690796852112\n2020-02-29 00:06:09.715238 Splitting test-training data (sentence #9 to test set)\n2020-02-29 00:06:09.738175 Creating model\n2020-02-29 00:06:09.814011 Compiling model\n2020-02-29 00:06:09.893760 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 1s 191us/step - loss: 0.6865 - accuracy: 0.5808\nEpoch 2/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.6281 - accuracy: 0.7242\nEpoch 3/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.5327 - accuracy: 0.7458\nEpoch 4/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4959 - accuracy: 0.7578\nEpoch 5/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4834 - accuracy: 0.7629\nEpoch 6/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.4729 - accuracy: 0.7711\nEpoch 7/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4647 - accuracy: 0.7767\nEpoch 8/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4543 - accuracy: 0.7849\nEpoch 9/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.4440 - accuracy: 0.7939\nEpoch 10/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4326 - accuracy: 0.7966\nEpoch 11/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.4182 - accuracy: 0.8074\nEpoch 12/30\n7798/7798 [==============================] - 1s 108us/step - loss: 0.4036 - accuracy: 0.8167\nEpoch 13/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.3867 - accuracy: 0.8312\nEpoch 14/30\n7798/7798 [==============================] - 1s 93us/step - loss: 0.3678 - accuracy: 0.8427\nEpoch 15/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.3477 - accuracy: 0.8533\nEpoch 16/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.3273 - accuracy: 0.8660\nEpoch 17/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.3043 - accuracy: 0.8830\nEpoch 18/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.2765 - accuracy: 0.8995\nEpoch 19/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.2516 - accuracy: 0.9154\nEpoch 20/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.2277 - accuracy: 0.9274\nEpoch 21/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.2052 - accuracy: 0.9365\nEpoch 22/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.1817 - accuracy: 0.9514\nEpoch 23/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.1613 - accuracy: 0.9585\nEpoch 24/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.1445 - accuracy: 0.9690\nEpoch 25/30\n7798/7798 [==============================] - 1s 78us/step - loss: 0.1272 - accuracy: 0.9747\nEpoch 26/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.1133 - accuracy: 0.9778\nEpoch 27/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.0989 - accuracy: 0.9824\nEpoch 28/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.0864 - accuracy: 0.9869\nEpoch 29/30\n7798/7798 [==============================] - 1s 80us/step - loss: 0.0776 - accuracy: 0.9876\nEpoch 30/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0685 - accuracy: 0.9905\n2020-02-29 00:06:37.650936 Evaluating model\n866/866 [==============================] - 1s 1ms/step\n2020-02-29 00:06:40.039717 Done evaluating, accuracy=0.7321016192436218\n2020-02-29 00:06:44.422835 Splitting test-training data (sentence #10 to test set)\n2020-02-29 00:06:44.454751 Creating model\n2020-02-29 00:06:44.521571 Compiling model\n2020-02-29 00:06:44.602355 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 2s 215us/step - loss: 0.6822 - accuracy: 0.5994\nEpoch 2/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.6070 - accuracy: 0.7283\nEpoch 3/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.5213 - accuracy: 0.7508\nEpoch 4/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.4919 - accuracy: 0.7656\nEpoch 5/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4764 - accuracy: 0.7735\nEpoch 6/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4638 - accuracy: 0.7807\nEpoch 7/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.4531 - accuracy: 0.7857\nEpoch 8/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.4411 - accuracy: 0.7924\nEpoch 9/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.4259 - accuracy: 0.7988\nEpoch 10/30\n7798/7798 [==============================] - 1s 86us/step - loss: 0.4098 - accuracy: 0.8132\nEpoch 11/30\n7798/7798 [==============================] - 1s 85us/step - loss: 0.3890 - accuracy: 0.8265\nEpoch 12/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.3669 - accuracy: 0.8427\nEpoch 13/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.3419 - accuracy: 0.8610\nEpoch 14/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.3135 - accuracy: 0.8770\nEpoch 15/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.2857 - accuracy: 0.8966\nEpoch 16/30\n7798/7798 [==============================] - 1s 84us/step - loss: 0.2570 - accuracy: 0.9159\nEpoch 17/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.2291 - accuracy: 0.9299\nEpoch 18/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.2020 - accuracy: 0.9468\nEpoch 19/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.1786 - accuracy: 0.9561\nEpoch 20/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.1556 - accuracy: 0.9652\nEpoch 21/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.1353 - accuracy: 0.9728\nEpoch 22/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.1165 - accuracy: 0.9795\nEpoch 23/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.1019 - accuracy: 0.9827\nEpoch 24/30\n7798/7798 [==============================] - 1s 79us/step - loss: 0.0880 - accuracy: 0.9873\nEpoch 25/30\n7798/7798 [==============================] - 1s 82us/step - loss: 0.0772 - accuracy: 0.9890\nEpoch 26/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0666 - accuracy: 0.9910\nEpoch 27/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0586 - accuracy: 0.9920\nEpoch 28/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0504 - accuracy: 0.9944\nEpoch 29/30\n7798/7798 [==============================] - 1s 83us/step - loss: 0.0442 - accuracy: 0.9950\nEpoch 30/30\n7798/7798 [==============================] - 1s 81us/step - loss: 0.0398 - accuracy: 0.9955\n2020-02-29 00:07:12.092573 Evaluating model\n866/866 [==============================] - 1s 1ms/step\n2020-02-29 00:07:14.522942 Done evaluating, accuracy=0.7355658411979675\n"
    }
   ],
   "source": [
    "# Q3.4 PART 1 do the 10-fold cross validation and store the results for each SVD component size\n",
    "# and store the results in 'q3_3_results'\n",
    "q3_4_svd_results = []\n",
    "for component_num in range(len(component_counts)):\n",
    "    q3_4_svd_results.append([])\n",
    "    for i in range(10):\n",
    "        svd = TruncatedSVD(n_components=component_counts[component_num])\n",
    "        svd_data = svd.fit_transform(full_tfidf)\n",
    "        training_x = []; training_y = []\n",
    "        test_x = []; test_y = []\n",
    "        log(\"Splitting test-training data (sentence #{} to test set)\".format(i+1))\n",
    "        for j in range(len(svd_data)):\n",
    "            if i == (j % 10):\n",
    "                # add when the counter values coincide, add the hot-ones for this sentence to the test set\n",
    "                test_x.append(np.array(svd_data[j])); test_y.append(Y[j])\n",
    "            else:\n",
    "                # add the hot-ones for this sentence to the training set\n",
    "                training_x.append(np.array(svd_data[j])); training_y.append(Y[j])\n",
    "\n",
    "        log(\"Creating model\"); q3_4_model = make_model(100, component_counts[component_num])\n",
    "\n",
    "        log(\"Compiling model\"); q3_4_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        log(\"Fitting model\"); q3_4_model.fit(np.array(training_x), np.array(training_y), epochs=30, batch_size=128)\n",
    "\n",
    "        log(\"Evaluating model\"); _, accuracy = q3_4_model.evaluate(np.array(test_x), np.array(test_y))\n",
    "        q3_4_svd_results[component_num].append(accuracy)\n",
    "\n",
    "        log(\"Done evaluating, accuracy={}\".format(q3_4_svd_results[component_num][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.6828143000602722, 0.6828143000602722, 0.7104959487915039, 0.6758939027786255, 0.7217090129852295, 0.7205542922019958, 0.6974595785140991, 0.6547344326972961, 0.7043879628181458, 0.7043879628181458]\naverage for 200 components in SVD: 0.6955251693725586\n[0.7139561772346497, 0.6816608905792236, 0.7301037907600403, 0.7393310070037842, 0.7401847839355469, 0.7321016192436218, 0.7136258482933044, 0.7078521847724915, 0.7170900702476501, 0.7297921180725098]\naverage for 300 components in SVD: 0.7205698490142822\n[0.7243368029594421, 0.7035755515098572, 0.7381775975227356, 0.7358708381652832, 0.7424942255020142, 0.7205542922019958, 0.7251732349395752, 0.6997690796852112, 0.7321016192436218, 0.7355658411979675]\naverage for 400 components in SVD: 0.7257619082927704\n"
    }
   ],
   "source": [
    "# write the results to the answer file\n",
    "q3_4_results_file = open(\"Q3_4_Results.txt\", \"w\")\n",
    "q3_4_results_file.write(\"PART 1: SVD component size optimization\\n\")\n",
    "q3_4_results_file.write(\"\\t1.\\tParameter chosen to optimize SVD was the number of components\\n\")\n",
    "q3_4_results_file.write(\"\\t2.\\tcomponent counts: {}\\n\".format(str(component_counts)))\n",
    "q3_4_svd_results_avg = [np.average(q3_4_svd_results[i]) for i in range(len(q3_4_svd_results))]\n",
    "max_component_count = component_counts[list(q3_4_svd_results_avg).index(np.max(q3_4_svd_results_avg))]\n",
    "for i in range(3):\n",
    "    print(str(q3_4_svd_results[i]))\n",
    "    print(\"average for {} components in SVD: {}\".format(component_counts[i], q3_4_svd_results_avg[i]))\n",
    "q3_4_results_file.write(\"\\t3.\\tAccuracy for Node Count:\\n\" +\\\n",
    "                        \"\\t\\t\\t{} components | avg. accuracy={}\\n\".format(component_counts[0], q3_4_svd_results_avg[0]) +\\\n",
    "                        \"\\t\\t\\t{} components | avg. accuracy={}\\n\".format(component_counts[1], q3_4_svd_results_avg[1]) +\\\n",
    "                        \"\\t\\t\\t{} components | avg. accuracy={}\\n\".format(component_counts[2], q3_4_svd_results_avg[2]))\n",
    "q3_4_results_file.write(\"\\t4.\\tChosen component count is {} because it had the highest average accuracy in the 10-fold cross validation.\\n\".format(max_component_count))\n",
    "q3_4_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "33us/step - loss: 0.2988 - accuracy: 0.8918\nEpoch 11/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.2544 - accuracy: 0.9164\nEpoch 12/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.2101 - accuracy: 0.9420\nEpoch 13/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.1703 - accuracy: 0.9624\nEpoch 14/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.1346 - accuracy: 0.9746\nEpoch 15/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.1065 - accuracy: 0.9841\nEpoch 16/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0840 - accuracy: 0.9878\nEpoch 17/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.0665 - accuracy: 0.9918\nEpoch 18/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0528 - accuracy: 0.9936\nEpoch 19/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0446 - accuracy: 0.9946\nEpoch 20/30\n7798/7798 [==============================] - 1s 129us/step - loss: 0.0365 - accuracy: 0.9958\nEpoch 21/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.0300 - accuracy: 0.9962\nEpoch 22/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.0253 - accuracy: 0.9973\nEpoch 23/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0217 - accuracy: 0.9978\nEpoch 24/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0193 - accuracy: 0.9979\nEpoch 25/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.0177 - accuracy: 0.9972\nEpoch 26/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0167 - accuracy: 0.9974\nEpoch 27/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.0143 - accuracy: 0.9979\nEpoch 28/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0149 - accuracy: 0.9977\nEpoch 29/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0143 - accuracy: 0.9972\nEpoch 30/30\n7798/7798 [==============================] - 1s 136us/step - loss: 0.0115 - accuracy: 0.9981\n2020-02-29 00:36:00.926139 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:36:04.818725 Done evaluating, accuracy=0.7667436599731445\n2020-02-29 00:36:09.704176 Splitting test-training data (sentence #6 to test set)\n2020-02-29 00:36:09.733099 Creating model\n2020-02-29 00:36:09.804909 Compiling model\n2020-02-29 00:36:09.888684 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 2s 311us/step - loss: 0.6681 - accuracy: 0.6454\nEpoch 2/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.5481 - accuracy: 0.7424\nEpoch 3/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.4937 - accuracy: 0.7603\nEpoch 4/30\n7798/7798 [==============================] - 1s 140us/step - loss: 0.4721 - accuracy: 0.7726\nEpoch 5/30\n7798/7798 [==============================] - 1s 136us/step - loss: 0.4518 - accuracy: 0.7829\nEpoch 6/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.4279 - accuracy: 0.8016\nEpoch 7/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.3997 - accuracy: 0.8259\nEpoch 8/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.3648 - accuracy: 0.8443\nEpoch 9/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.3231 - accuracy: 0.8727\nEpoch 10/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.2773 - accuracy: 0.9072\nEpoch 11/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.2303 - accuracy: 0.9293\nEpoch 12/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.1864 - accuracy: 0.9563\nEpoch 13/30\n7798/7798 [==============================] - 1s 129us/step - loss: 0.1489 - accuracy: 0.9715\nEpoch 14/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.1178 - accuracy: 0.9801\nEpoch 15/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.0930 - accuracy: 0.9878\nEpoch 16/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.0753 - accuracy: 0.9905\nEpoch 17/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.0600 - accuracy: 0.9926\nEpoch 18/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.0485 - accuracy: 0.9955\nEpoch 19/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.0402 - accuracy: 0.9955\nEpoch 20/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.0337 - accuracy: 0.9964\nEpoch 21/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.0290 - accuracy: 0.9971\nEpoch 22/30\n7798/7798 [==============================] - 1s 128us/step - loss: 0.0241 - accuracy: 0.9978\nEpoch 23/30\n7798/7798 [==============================] - 1s 161us/step - loss: 0.0207 - accuracy: 0.9979\nEpoch 24/30\n7798/7798 [==============================] - 1s 153us/step - loss: 0.0185 - accuracy: 0.9978\nEpoch 25/30\n7798/7798 [==============================] - 1s 159us/step - loss: 0.0162 - accuracy: 0.9981\nEpoch 26/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.0146 - accuracy: 0.9985\nEpoch 27/30\n7798/7798 [==============================] - 1s 149us/step - loss: 0.0133 - accuracy: 0.9982\nEpoch 28/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.0121 - accuracy: 0.9985\nEpoch 29/30\n7798/7798 [==============================] - 1s 151us/step - loss: 0.0107 - accuracy: 0.9986\nEpoch 30/30\n7798/7798 [==============================] - 1s 143us/step - loss: 0.0096 - accuracy: 0.9987\n2020-02-29 00:36:54.860910 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:36:58.786090 Done evaluating, accuracy=0.7482678890228271\n2020-02-29 00:37:04.621995 Splitting test-training data (sentence #7 to test set)\n2020-02-29 00:37:04.667872 Creating model\n2020-02-29 00:37:04.776579 Compiling model\n2020-02-29 00:37:04.868369 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 4s 450us/step - loss: 0.6767 - accuracy: 0.6317\nEpoch 2/30\n7798/7798 [==============================] - 2s 192us/step - loss: 0.5591 - accuracy: 0.7351\nEpoch 3/30\n7798/7798 [==============================] - 1s 189us/step - loss: 0.4894 - accuracy: 0.7631\nEpoch 4/30\n7798/7798 [==============================] - 1s 189us/step - loss: 0.4691 - accuracy: 0.7737\nEpoch 5/30\n7798/7798 [==============================] - 1s 163us/step - loss: 0.4504 - accuracy: 0.7856\nEpoch 6/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.4321 - accuracy: 0.7971\nEpoch 7/30\n7798/7798 [==============================] - 1s 152us/step - loss: 0.4058 - accuracy: 0.8137\nEpoch 8/30\n7798/7798 [==============================] - 1s 165us/step - loss: 0.3771 - accuracy: 0.8341\nEpoch 9/30\n7798/7798 [==============================] - 1s 160us/step - loss: 0.3387 - accuracy: 0.8632\nEpoch 10/30\n7798/7798 [==============================] - 1s 143us/step - loss: 0.2980 - accuracy: 0.8896\nEpoch 11/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.2555 - accuracy: 0.9195\nEpoch 12/30\n7798/7798 [==============================] - 1s 152us/step - loss: 0.2113 - accuracy: 0.9446\nEpoch 13/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.1711 - accuracy: 0.9615\nEpoch 14/30\n7798/7798 [==============================] - 1s 166us/step - loss: 0.1368 - accuracy: 0.9724\nEpoch 15/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.1091 - accuracy: 0.9803\nEpoch 16/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.0876 - accuracy: 0.9872\nEpoch 17/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0689 - accuracy: 0.9905\nEpoch 18/30\n7798/7798 [==============================] - 1s 128us/step - loss: 0.0563 - accuracy: 0.9928\nEpoch 19/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.0457 - accuracy: 0.9941\nEpoch 20/30\n7798/7798 [==============================] - 1s 170us/step - loss: 0.0386 - accuracy: 0.9955\nEpoch 21/30\n7798/7798 [==============================] - 1s 153us/step - loss: 0.0324 - accuracy: 0.9964\nEpoch 22/30\n7798/7798 [==============================] - 1s 137us/step - loss: 0.0277 - accuracy: 0.9965\nEpoch 23/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.0246 - accuracy: 0.9964\nEpoch 24/30\n7798/7798 [==============================] - 1s 137us/step - loss: 0.0215 - accuracy: 0.9968\nEpoch 25/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.0192 - accuracy: 0.9971\nEpoch 26/30\n7798/7798 [==============================] - 1s 146us/step - loss: 0.0172 - accuracy: 0.9978\nEpoch 27/30\n7798/7798 [==============================] - 1s 163us/step - loss: 0.0151 - accuracy: 0.9974\nEpoch 28/30\n7798/7798 [==============================] - 1s 156us/step - loss: 0.0146 - accuracy: 0.9978\nEpoch 29/30\n7798/7798 [==============================] - 1s 156us/step - loss: 0.0127 - accuracy: 0.9978\nEpoch 30/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0120 - accuracy: 0.9981\n2020-02-29 00:37:57.089132 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:38:00.993743 Done evaluating, accuracy=0.7309468984603882\n2020-02-29 00:38:05.826520 Splitting test-training data (sentence #8 to test set)\n2020-02-29 00:38:05.858435 Creating model\n2020-02-29 00:38:05.939219 Compiling model\n2020-02-29 00:38:06.024991 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 2s 313us/step - loss: 0.6771 - accuracy: 0.6323\nEpoch 2/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.5600 - accuracy: 0.7476\nEpoch 3/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.4895 - accuracy: 0.7622\nEpoch 4/30\n7798/7798 [==============================] - 1s 135us/step - loss: 0.4699 - accuracy: 0.7770\nEpoch 5/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.4534 - accuracy: 0.7846\nEpoch 6/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.4356 - accuracy: 0.7993\nEpoch 7/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.4099 - accuracy: 0.8121\nEpoch 8/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.3802 - accuracy: 0.8288\nEpoch 9/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.3408 - accuracy: 0.8609\nEpoch 10/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.2952 - accuracy: 0.8932\nEpoch 11/30\n7798/7798 [==============================] - 1s 134us/step - loss: 0.2463 - accuracy: 0.9238\nEpoch 12/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.1999 - accuracy: 0.9496\nEpoch 13/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.1577 - accuracy: 0.9651\nEpoch 14/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.1239 - accuracy: 0.9773\nEpoch 15/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0976 - accuracy: 0.9844\nEpoch 16/30\n7798/7798 [==============================] - 1s 125us/step - loss: 0.0748 - accuracy: 0.9905\nEpoch 17/30\n7798/7798 [==============================] - 1s 125us/step - loss: 0.0596 - accuracy: 0.9940\nEpoch 18/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0497 - accuracy: 0.9937\nEpoch 19/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0391 - accuracy: 0.9959\nEpoch 20/30\n7798/7798 [==============================] - 1s 123us/step - loss: 0.0330 - accuracy: 0.9959\nEpoch 21/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0279 - accuracy: 0.9968\nEpoch 22/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.0234 - accuracy: 0.9969\nEpoch 23/30\n7798/7798 [==============================] - 1s 129us/step - loss: 0.0206 - accuracy: 0.9974\nEpoch 24/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0183 - accuracy: 0.9978\nEpoch 25/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0160 - accuracy: 0.9976\nEpoch 26/30\n7798/7798 [==============================] - 1s 126us/step - loss: 0.0143 - accuracy: 0.9977\nEpoch 27/30\n7798/7798 [==============================] - 1s 126us/step - loss: 0.0146 - accuracy: 0.9978\nEpoch 28/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.0120 - accuracy: 0.9982\nEpoch 29/30\n7798/7798 [==============================] - 1s 123us/step - loss: 0.0135 - accuracy: 0.9974\nEpoch 30/30\n7798/7798 [==============================] - 1s 124us/step - loss: 0.0102 - accuracy: 0.9983\n2020-02-29 00:38:49.421740 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:38:53.348735 Done evaluating, accuracy=0.7124711275100708\n2020-02-29 00:38:59.558100 Splitting test-training data (sentence #9 to test set)\n2020-02-29 00:38:59.600988 Creating model\n2020-02-29 00:38:59.702713 Compiling model\n2020-02-29 00:38:59.803444 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 3s 392us/step - loss: 0.6726 - accuracy: 0.6152\nEpoch 2/30\n7798/7798 [==============================] - 1s 179us/step - loss: 0.5589 - accuracy: 0.7357\nEpoch 3/30\n7798/7798 [==============================] - 1s 169us/step - loss: 0.4965 - accuracy: 0.7578\nEpoch 4/30\n7798/7798 [==============================] - 1s 149us/step - loss: 0.4715 - accuracy: 0.7757\nEpoch 5/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.4501 - accuracy: 0.7887\nEpoch 6/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.4265 - accuracy: 0.8048\nEpoch 7/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.3939 - accuracy: 0.8288\nEpoch 8/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.3565 - accuracy: 0.8555\nEpoch 9/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.3113 - accuracy: 0.8878\nEpoch 10/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.2678 - accuracy: 0.9142\nEpoch 11/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.2203 - accuracy: 0.9413\nEpoch 12/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.1781 - accuracy: 0.9585\nEpoch 13/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.1431 - accuracy: 0.9728\nEpoch 14/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.1141 - accuracy: 0.9781\nEpoch 15/30\n7798/7798 [==============================] - 1s 140us/step - loss: 0.0913 - accuracy: 0.9856\nEpoch 16/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.0722 - accuracy: 0.9895\nEpoch 17/30\n7798/7798 [==============================] - 1s 143us/step - loss: 0.0581 - accuracy: 0.9924\nEpoch 18/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0462 - accuracy: 0.9950\nEpoch 19/30\n7798/7798 [==============================] - 1s 143us/step - loss: 0.0382 - accuracy: 0.9959\nEpoch 20/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0322 - accuracy: 0.9958\nEpoch 21/30\n7798/7798 [==============================] - 1s 143us/step - loss: 0.0273 - accuracy: 0.9969\nEpoch 22/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.0238 - accuracy: 0.9969\nEpoch 23/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0213 - accuracy: 0.9968\nEpoch 24/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0213 - accuracy: 0.9968\nEpoch 25/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.0171 - accuracy: 0.9978\nEpoch 26/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.0151 - accuracy: 0.9974\nEpoch 27/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.0130 - accuracy: 0.9985\nEpoch 28/30\n7798/7798 [==============================] - 1s 159us/step - loss: 0.0126 - accuracy: 0.9979\nEpoch 29/30\n7798/7798 [==============================] - 1s 180us/step - loss: 0.0107 - accuracy: 0.9987\nEpoch 30/30\n7798/7798 [==============================] - 1s 178us/step - loss: 0.0098 - accuracy: 0.9986\n2020-02-29 00:39:50.382210 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:39:54.763635 Done evaluating, accuracy=0.7551963329315186\n2020-02-29 00:39:59.596293 Splitting test-training data (sentence #10 to test set)\n2020-02-29 00:39:59.629205 Creating model\n2020-02-29 00:39:59.705004 Compiling model\n2020-02-29 00:39:59.780800 Fitting model\nEpoch 1/30\n7798/7798 [==============================] - 3s 405us/step - loss: 0.6737 - accuracy: 0.6295\nEpoch 2/30\n7798/7798 [==============================] - 1s 152us/step - loss: 0.5602 - accuracy: 0.7447\nEpoch 3/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.4983 - accuracy: 0.7570\nEpoch 4/30\n7798/7798 [==============================] - 1s 146us/step - loss: 0.4754 - accuracy: 0.7716\nEpoch 5/30\n7798/7798 [==============================] - 1s 144us/step - loss: 0.4578 - accuracy: 0.7789\nEpoch 6/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.4369 - accuracy: 0.7971\nEpoch 7/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.4125 - accuracy: 0.8098\nEpoch 8/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.3795 - accuracy: 0.8347\nEpoch 9/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.3444 - accuracy: 0.8598\nEpoch 10/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.3021 - accuracy: 0.8893\nEpoch 11/30\n7798/7798 [==============================] - 1s 132us/step - loss: 0.2576 - accuracy: 0.9177\nEpoch 12/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.2126 - accuracy: 0.9423\nEpoch 13/30\n7798/7798 [==============================] - 1s 127us/step - loss: 0.1719 - accuracy: 0.9629\nEpoch 14/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.1380 - accuracy: 0.9744\nEpoch 15/30\n7798/7798 [==============================] - 1s 131us/step - loss: 0.1085 - accuracy: 0.9815\nEpoch 16/30\n7798/7798 [==============================] - 1s 129us/step - loss: 0.0869 - accuracy: 0.9874\nEpoch 17/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0690 - accuracy: 0.9910\nEpoch 18/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0559 - accuracy: 0.9938\nEpoch 19/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.0454 - accuracy: 0.9953\nEpoch 20/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.0393 - accuracy: 0.9956\nEpoch 21/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.0316 - accuracy: 0.9965\nEpoch 22/30\n7798/7798 [==============================] - 1s 142us/step - loss: 0.0285 - accuracy: 0.9972\nEpoch 23/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.0238 - accuracy: 0.9976\nEpoch 24/30\n7798/7798 [==============================] - 1s 137us/step - loss: 0.0197 - accuracy: 0.9981\nEpoch 25/30\n7798/7798 [==============================] - 1s 139us/step - loss: 0.0176 - accuracy: 0.9979\nEpoch 26/30\n7680/7798 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.997798/7798 [==============================] - 1s 137us/step - loss: 0.0156 - accuracy: 0.9985\nEpoch 27/30\n7798/7798 [==============================] - 1s 141us/step - loss: 0.0142 - accuracy: 0.9985\nEpoch 28/30\n7798/7798 [==============================] - 1s 138us/step - loss: 0.0123 - accuracy: 0.9983\nEpoch 29/30\n7798/7798 [==============================] - 1s 133us/step - loss: 0.0112 - accuracy: 0.9988\nEpoch 30/30\n7798/7798 [==============================] - 1s 130us/step - loss: 0.0099 - accuracy: 0.9983\n2020-02-29 00:40:46.805607 Evaluating model\n866/866 [==============================] - 1s 2ms/step\n2020-02-29 00:40:50.619350 Done evaluating, accuracy=0.7459584474563599\n"
    }
   ],
   "source": [
    "# Q3.4 PART 2 do the 10-fold cross validation with optimal SVD components and store the results for \n",
    "# each model's nodes in layer 1 in 'q3_4_nn_results'\n",
    "q3_4_nn_results = []\n",
    "for node_num in range(len(nodes)):\n",
    "    q3_4_nn_results.append([])\n",
    "    for i in range(10):\n",
    "        svd = TruncatedSVD(n_components=max_component_count)\n",
    "        svd_data = svd.fit_transform(full_tfidf)\n",
    "        training_x = []; training_y = []\n",
    "        test_x = []; test_y = []\n",
    "        log(\"Splitting test-training data (sentence #{} to test set)\".format(i+1))\n",
    "        for j in range(len(svd_data)):\n",
    "            if i == (j % 10):\n",
    "                # add when the counter values coincide, add the hot-ones for this sentence to the test set\n",
    "                test_x.append(np.array(svd_data[j])); test_y.append(Y[j])\n",
    "            else:\n",
    "                # add the hot-ones for this sentence to the training set\n",
    "                training_x.append(np.array(svd_data[j])); training_y.append(Y[j])\n",
    "\n",
    "        log(\"Creating model\"); q3_4_model = make_model(nodes[node_num], max_component_count)\n",
    "\n",
    "        log(\"Compiling model\"); q3_4_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        log(\"Fitting model\"); q3_4_model.fit(np.array(training_x), np.array(training_y), epochs=30, batch_size=128)\n",
    "\n",
    "        log(\"Evaluating model\"); _, accuracy = q3_4_model.evaluate(np.array(test_x), np.array(test_y))\n",
    "        q3_4_nn_results[node_num].append(accuracy)\n",
    "\n",
    "        log(\"Done evaluating, accuracy={}\".format(q3_4_nn_results[node_num][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.7370242476463318, 0.7185697555541992, 0.722029983997345, 0.7497116327285767, 0.7621247172355652, 0.7690531015396118, 0.7309468984603882, 0.6974595785140991, 0.7586604952812195, 0.7355658411979675]\naverage for 100 components in SVD: 0.7381146252155304\n[0.7162629961967468, 0.7185697555541992, 0.7197231650352478, 0.7277969717979431, 0.7736720442771912, 0.7436489462852478, 0.7321016192436218, 0.7066974639892578, 0.7459584474563599, 0.7551963329315186]\naverage for 200 components in SVD: 0.7339627742767334\n[0.7254902124404907, 0.70126873254776, 0.7185697555541992, 0.7427912354469299, 0.7667436599731445, 0.7482678890228271, 0.7309468984603882, 0.7124711275100708, 0.7551963329315186, 0.7459584474563599]\naverage for 300 components in SVD: 0.7347704291343689\n"
    }
   ],
   "source": [
    "# write the results to the answer file\n",
    "q3_4_results_file = open(\"Q3_4_Results.txt\", \"a\")\n",
    "q3_4_results_file.write(\"PART 2: Neural net node count optimization\\n\")\n",
    "q3_4_results_file.write(\"\\t1.\\tParameter chosen to optimize model was the number of nodes in 1st hidden layer\\n\")\n",
    "q3_4_results_file.write(\"\\t2.\\tNode counts: {}\\n\".format(str(nodes)))\n",
    "q3_4_nn_results_avg = [np.average(q3_4_nn_results[i]) for i in range(len(q3_4_nn_results))]\n",
    "max_node_count = nodes[list(q3_4_nn_results_avg).index(np.max(q3_4_nn_results_avg))]\n",
    "for i in range(3):\n",
    "    print(str(q3_4_nn_results[i]))\n",
    "    print(\"average for {} components in SVD: {}\".format(nodes[i], q3_4_nn_results_avg[i]))\n",
    "q3_4_results_file.write(\"\\t3.\\tAccuracy for Node Count:\\n\" +\\\n",
    "                        \"\\t\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[0], q3_4_nn_results_avg[0]) +\\\n",
    "                        \"\\t\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[1], q3_4_nn_results_avg[1]) +\\\n",
    "                        \"\\t\\t\\t{} nodes | avg. accuracy={}\\n\".format(nodes[2], q3_4_nn_results_avg[2]))\n",
    "q3_4_results_file.write(\"\\t4.\\tChosen node count is {} because it had the highest average accuracy in the 10-fold cross validation.\\n\".format(max_node_count))\n",
    "q3_4_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-29 00:40:55.117908 Creating model\n2020-02-29 00:40:55.194703 Compiling model\n2020-02-29 00:40:55.269633 Fitting model\nEpoch 1/30\n8664/8664 [==============================] - 2s 276us/step - loss: 0.6823 - accuracy: 0.6049\nEpoch 2/30\n8664/8664 [==============================] - 2s 181us/step - loss: 0.5971 - accuracy: 0.7297\nEpoch 3/30\n8664/8664 [==============================] - 1s 166us/step - loss: 0.5116 - accuracy: 0.7514\nEpoch 4/30\n8664/8664 [==============================] - 1s 150us/step - loss: 0.4863 - accuracy: 0.7637\nEpoch 5/30\n8664/8664 [==============================] - 1s 127us/step - loss: 0.4750 - accuracy: 0.7708\nEpoch 6/30\n8664/8664 [==============================] - 1s 114us/step - loss: 0.4656 - accuracy: 0.7774\nEpoch 7/30\n8664/8664 [==============================] - 1s 106us/step - loss: 0.4547 - accuracy: 0.7797\nEpoch 8/30\n8664/8664 [==============================] - 1s 105us/step - loss: 0.4437 - accuracy: 0.7899\nEpoch 9/30\n8664/8664 [==============================] - 1s 104us/step - loss: 0.4298 - accuracy: 0.8004\nEpoch 10/30\n8664/8664 [==============================] - 1s 106us/step - loss: 0.4148 - accuracy: 0.8074\nEpoch 11/30\n8664/8664 [==============================] - 1s 107us/step - loss: 0.3975 - accuracy: 0.8243\nEpoch 12/30\n8664/8664 [==============================] - 1s 108us/step - loss: 0.3767 - accuracy: 0.8363\nEpoch 13/30\n8664/8664 [==============================] - 1s 106us/step - loss: 0.3549 - accuracy: 0.8525\nEpoch 14/30\n8664/8664 [==============================] - 1s 106us/step - loss: 0.3307 - accuracy: 0.8673\nEpoch 15/30\n8664/8664 [==============================] - 1s 106us/step - loss: 0.3056 - accuracy: 0.8840\nEpoch 16/30\n8664/8664 [==============================] - 1s 104us/step - loss: 0.2788 - accuracy: 0.9006\nEpoch 17/30\n8664/8664 [==============================] - 1s 126us/step - loss: 0.2525 - accuracy: 0.9141\nEpoch 18/30\n8664/8664 [==============================] - 1s 122us/step - loss: 0.2256 - accuracy: 0.9286\nEpoch 19/30\n8664/8664 [==============================] - 1s 121us/step - loss: 0.2008 - accuracy: 0.9418\nEpoch 20/30\n8664/8664 [==============================] - 1s 110us/step - loss: 0.1771 - accuracy: 0.9531\nEpoch 21/30\n8664/8664 [==============================] - 1s 105us/step - loss: 0.1559 - accuracy: 0.9628\nEpoch 22/30\n8664/8664 [==============================] - 1s 126us/step - loss: 0.1360 - accuracy: 0.9694\nEpoch 23/30\n8664/8664 [==============================] - 1s 122us/step - loss: 0.1188 - accuracy: 0.9768\nEpoch 24/30\n8664/8664 [==============================] - 1s 107us/step - loss: 0.1036 - accuracy: 0.9803\nEpoch 25/30\n8664/8664 [==============================] - 1s 110us/step - loss: 0.0903 - accuracy: 0.9837\nEpoch 26/30\n8664/8664 [==============================] - 1s 120us/step - loss: 0.0801 - accuracy: 0.9866\nEpoch 27/30\n8664/8664 [==============================] - 1s 108us/step - loss: 0.0685 - accuracy: 0.9889\nEpoch 28/30\n8664/8664 [==============================] - 1s 110us/step - loss: 0.0588 - accuracy: 0.9924\nEpoch 29/30\n8664/8664 [==============================] - 1s 109us/step - loss: 0.0518 - accuracy: 0.9926\nEpoch 30/30\n8664/8664 [==============================] - 1s 108us/step - loss: 0.0462 - accuracy: 0.9942\n2020-02-29 00:41:38.667811 Evaluating model\n8664/8664 [==============================] - 3s 313us/step\n2020-02-29 00:41:43.912274 Done evaluating, accuracy=0.9960756897926331\n"
    }
   ],
   "source": [
    "# retrain the model on the entire training set and report the accuracy on the training set as an upper-bound for performance on test data\n",
    "svd = TruncatedSVD(n_components=max_component_count)\n",
    "svd_data = svd.fit_transform(full_tfidf)\n",
    "\n",
    "log(\"Creating model\"); q3_4_model = make_model(max_node_count, max_component_count)\n",
    "\n",
    "log(\"Compiling model\"); q3_4_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "log(\"Fitting model\"); q3_4_model.fit(np.array(svd_data), np.array(Y), epochs=30, batch_size=128)\n",
    "\n",
    "log(\"Evaluating model\"); q3_4_loss, q3_4_accuracy = q3_4_model.evaluate(np.array(svd_data), np.array(Y))\n",
    "\n",
    "log(\"Done evaluating, accuracy={}\".format(q3_4_accuracy))\n",
    "\n",
    "q3_4_results_file = open(\"Q3_4_Results.txt\", \"a\")\n",
    "q3_4_results_file.write(\"PART 3: Upper bound accuracy\\n\")\n",
    "q3_4_results_file.write(\"\\t5.\\tTrainied model on full data with {} nodes and {} SVD components\\n\".format(max_node_count, max_component_count))\n",
    "q3_4_results_file.write(\"\\t\\t\\taccuracy = {} ; loss = {}\\n\".format(q3_4_accuracy, q3_4_loss))\n",
    "q3_4_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2020-02-29 00:41:43.970119 building one-hot test array\n2020-02-29 00:42:43.511047 one-hot test array done\n"
    }
   ],
   "source": [
    "# find the best of the three models and use it to annotate the test data\n",
    "# with positive/negative predictions\n",
    "\n",
    "testfile = open(\"test_reviews.txt\", \"r\")\n",
    "testfile_sents = [sentence.strip().lower() for sentence in testfile.readlines()]\n",
    "testfile_data = [[word for word in sentence] for sentence in testfile_sents]\n",
    "testfile.close()\n",
    "\n",
    "q3_5_results_file = open(\"Q3_5_Results.txt\", \"w\")\n",
    "model_accuracies = [q3_2_accuracy, q3_3_accuracy, q3_4_accuracy]\n",
    "best_model_num = list(model_accuracies).index(np.max(model_accuracies))\n",
    "q3_5_results_file.write(\"Accuracies for Models:\\n\" +\\\n",
    "    \"\\t\\t- One-Hot = {}\\n\\t\\t- Word2Vec = {}\\n\\t\\t- SVD = {}\\n\".format(q3_2_accuracy, q3_3_accuracy, q3_4_accuracy))\n",
    "\n",
    "if best_model_num == 0:\n",
    "    q3_5_results_file.write(\"One-Hot Encoding Used:\\n\")\n",
    "\n",
    "    log('building one-hot test array')\n",
    "    onehot_test = np.array([np.array([1 if word in sentence else 0 for word in full_vocab]) for sentence in testfile_data])\n",
    "    log(\"one-hot test array done\")\n",
    "\n",
    "    raw_results = q3_2_model.predict(onehot_test)\n",
    "elif best_model_num == 1:\n",
    "    q3_5_results_file.write(\"Word2Vec Encoding Used:\\n\")\n",
    "\n",
    "    log('building word2vec test array')\n",
    "    word2vec_test = []\n",
    "    for sentence in testfile_data:\n",
    "        sentence_vec = get_sentence_vector(sentence)\n",
    "        if np.isnan(sentence_vec).any():\n",
    "            sentence_vec = np.zeros(300)\n",
    "        word2vec.append(sentence_vec)\n",
    "    log(\"word2vec test array done\")\n",
    "\n",
    "    raw_results = q3_3_model.predict(word2vec_test)\n",
    "else:\n",
    "    q3_5_results_file.write(\"SVD Used:\\n\")\n",
    "\n",
    "    log('building svd test array')\n",
    "    svd = TruncatedSVD(n_components=max_component_count)\n",
    "    svd_data = svd.fit_transform(full_tfidf)\n",
    "    log('svd test array done')\n",
    "\n",
    "    raw_results = q3_4_model.predict(svd_test)\n",
    "\n",
    "# print the results of the prediction to the file, and close\n",
    "results = [1 if out>0.5 else 0 for out in raw_results]\n",
    "for i in range(len(results)):\n",
    "    q3_5_results_file.write(\"{} : {}\\n\".format(results[i], testfile_sents[i]))\n",
    "q3_5_results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}