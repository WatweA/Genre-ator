{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log(message):\n",
    "    print(datetime.now().strftime(\"%H:%M:%S -\"), message)\n",
    "    \n",
    "def printnow():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:40:24 - Reading data from files\n21:40:24 - Done\n\n"
    }
   ],
   "source": [
    "# Create the dictionary of dataframes for training and testing\n",
    "section_headers = ['Intro','Verse','Refrain','Pre-Chorus','Chorus','Post-Chorus','Hooks','Riffs/Basslines','Scratches','Sampling','Bridge','Interlude','Skit','Collision','Instrumental','Solo','Ad-lib','Segue','Outro']\n",
    "header_strip_list = '|'.join(['\\[' + header + '\\]' for header in section_headers])\n",
    "\n",
    "def header_to_filename(train, header):\n",
    "    if train: return 'section_train_test/train_' + header.replace('/', '_').lower() + '.zip'\n",
    "    else: return 'section_train_test/test_' + header.replace('/', '_').lower() + '.zip'\n",
    "\n",
    "log('Reading data from files')\n",
    "train_dfs = {header:pd.read_pickle(header_to_filename(1, header)) for header in section_headers}\n",
    "test_dfs = {header:pd.read_pickle(header_to_filename(0, header)) for header in section_headers}\n",
    "log('Done\\n')\n",
    "\n",
    "# For dataframes without samples of each genre, add the empty string as lyrics for all genres\n",
    "dummy_df = pd.DataFrame(data={'lyrics' : 8*[''], 'genre' : 2*['country', 'hiphop', 'pop', 'rock']})\n",
    "for header in section_headers:\n",
    "    if len(train_dfs[header]) < 5: train_dfs[header] = pd.concat([train_dfs[header], dummy_df])\n",
    "    if len(test_dfs[header]) < 5: test_dfs[header] = pd.concat([test_dfs[header], dummy_df])\n",
    "    train_dfs[header] = train_dfs[header].reset_index(drop=True)\n",
    "    test_dfs[header] = test_dfs[header].reset_index(drop=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:40:26 - Finding the counts of each section type in the corpus\n1 Intro: 1056\n2 Verse: 11248\n3 Refrain: 438\n4 Pre-Chorus: 4128\n5 Chorus: 13602\n6 Post-Chorus: 1029\n7 Hooks: 16\n8 Riffs/Basslines: 16\n9 Scratches: 16\n10 Sampling: 16\n11 Bridge: 3417\n12 Interlude: 259\n13 Skit: 17\n14 Collision: 18\n15 Instrumental: 190\n16 Solo: 177\n17 Ad-lib: 19\n18 Segue: 16\n19 Outro: 2332\n21:40:26 - Done: total length is 38010\n\n21:40:26 - Finding the percent frequencies of each section type in the corpus\n1 Intro: 0.027782162588792424\n2 Verse: 0.2959221257563799\n3 Refrain: 0.011523283346487766\n4 Pre-Chorus: 0.10860299921073402\n5 Chorus: 0.3578531965272297\n6 Post-Chorus: 0.02707182320441989\n7 Hooks: 0.0004209418574059458\n8 Riffs/Basslines: 0.0004209418574059458\n9 Scratches: 0.0004209418574059458\n10 Sampling: 0.0004209418574059458\n11 Bridge: 0.0898973954222573\n12 Interlude: 0.006813996316758748\n13 Skit: 0.00044725072349381743\n14 Collision: 0.00047355958958168905\n15 Instrumental: 0.004998684556695606\n16 Solo: 0.004656669297553276\n17 Ad-lib: 0.0004998684556695607\n18 Segue: 0.0004209418574059458\n19 Outro: 0.0613522757169166\n21:40:26 - Done\n\n"
    }
   ],
   "source": [
    "log('Finding the counts of each section type in the corpus')\n",
    "total_length = 0\n",
    "for i,header in enumerate(section_headers):\n",
    "    length = len(train_dfs[header]) + len(test_dfs[header])\n",
    "    print(i + 1, header + ':', length)\n",
    "    total_length += len(train_dfs[header]) + len(test_dfs[header])\n",
    "log(f'Done: total length is {total_length}\\n')\n",
    "\n",
    "log('Finding the percent frequencies of each section type in the corpus')\n",
    "corpus_weights = {}\n",
    "for i,header in enumerate(section_headers):\n",
    "    frequency = (len(train_dfs[header]) + len(test_dfs[header])) / total_length\n",
    "    print(i + 1, header + ':', frequency)\n",
    "    corpus_weights[header] = frequency\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:40:28 - Training TF-IDF Vectorizer on all 4921 lyrics\n21:40:40 - Fitting SVD on all lyrics\n21:42:25 - Done\n\n"
    }
   ],
   "source": [
    "# Load nonredundant data\n",
    "country_df = pd.read_pickle(r'train_test_data/country_data.zip')\n",
    "country_df['genre'] = 'country'\n",
    "hiphop_df = pd.read_pickle(r'train_test_data/hiphop_data.zip')\n",
    "hiphop_df['genre'] = 'hiphop'\n",
    "pop_df = pd.read_pickle(r'train_test_data/pop_data.zip')\n",
    "pop_df['genre'] = 'pop'\n",
    "rock_df = pd.read_pickle(r'train_test_data/rock_data.zip')\n",
    "rock_df['genre'] = 'rock'\n",
    "full_df = pd.concat([country_df,hiphop_df, pop_df,rock_df])\n",
    "full_df.reset_index(inplace=True, drop=True)\n",
    "full_df\n",
    "\n",
    "# Combine lyrics into one list to be input for tf-idf vectorizer WITH UNIGRAMS UP TO TRIGRAMS\n",
    "full_lyrics = [lyrics.lower() for lyrics in full_df['lyrics']]\n",
    "log(f'Training TF-IDF Vectorizer on all {len(full_lyrics)} lyrics')\n",
    "tfidf_ngram_vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,3)).fit(full_lyrics)\n",
    "tfidf_ngram_features = tfidf_ngram_vectorizer.get_feature_names()\n",
    "tfidf_ngram_data = tfidf_ngram_vectorizer.transform(full_lyrics)\n",
    "log('Fitting SVD on all lyrics')\n",
    "svd_ngram = TruncatedSVD(n_components=500).fit(tfidf_ngram_data)\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:42:25 - Encoding the training data\n21:42:48 - Done\n\n21:42:48 - Encoding the testing data\n21:43:10 - Done\n\n"
    }
   ],
   "source": [
    "# Create TFIDF up to trigram encoding for nonredundant data\n",
    "def encode_tfidf_ngram_svd(df): \n",
    "    tfidf_ngram_vec = tfidf_ngram_vectorizer.transform(df['lyrics'].values)\n",
    "    svd_ngram_vec = svd_ngram.transform(tfidf_ngram_vec)\n",
    "    tfidf_ngram_df = pd.DataFrame(svd_ngram_vec)\n",
    "    tfidf_ngram_df['y'] = df['genre']\n",
    "    return tfidf_ngram_df\n",
    "\n",
    "# Create the training and testing encoded dataframes\n",
    "log('Encoding the training data')\n",
    "tfidf_train = {header:encode_tfidf_ngram_svd(train_dfs[header]) for header in section_headers}\n",
    "log('Done\\n')\n",
    "\n",
    "log('Encoding the testing data')\n",
    "tfidf_test = {header:encode_tfidf_ngram_svd(test_dfs[header]) for header in section_headers}\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "15:23:29 - Loading the raw string data\n15:23:29 - Done\n\n15:23:29 - Splitting the raw string data\n15:23:30 - Done\n\n"
    }
   ],
   "source": [
    "# Load the string lyrics data to make predictions\n",
    "log('Loading the raw string data')\n",
    "string_train = pd.read_pickle(r'train_test_data/train.zip')\n",
    "string_test = pd.read_pickle(r'train_test_data/test.zip')\n",
    "log('Done\\n')\n",
    "\n",
    "# splits the given lyrics by section \n",
    "def split_by_section(lyrics):\n",
    "    headers = [word[1:-1] for word in lyrics.split() if word[0] == '[' and word[-1] == ']' and word[1:-1] in section_headers]\n",
    "    split_sections = re.split(header_strip_list, lyrics)\n",
    "    ret_sections = []\n",
    "    for section in split_sections:\n",
    "        mod_section = section.replace('[END]','').replace('[START]','').strip()\n",
    "        if not(mod_section in ['', ' ','\\n']): ret_sections.append(mod_section)\n",
    "    return list(zip(headers, ret_sections))\n",
    "\n",
    "# Turn the raw string data into tuples of section strings and the lyrics of that section\n",
    "log('Splitting the raw string data')\n",
    "split_string_train = string_train\n",
    "split_string_train['lyrics'] = string_train['lyrics'].map(split_by_section)\n",
    "split_string_test = string_test\n",
    "split_string_test['lyrics'] = string_test['lyrics'].map(split_by_section)\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16:06:23 - Splitting the encoding string lyrics of each section\n16:06:23 - \tTesting set\n16:22:34 - \tTraining set\n16:31:18 - ValueError0\t[]\n16:42:28 - ValueError0\t[]\n17:11:53 - ValueError0\t[]\n17:29:41 - ValueError0\t[]\n17:31:14 - Done\n\n"
    }
   ],
   "source": [
    "# Encode the split string data with TFIDF (up to trigrams) and SVD \n",
    "def split_lyrics_encode(split_lyrics):\n",
    "    sections_array = [section for section,lyrics in split_lyrics]\n",
    "    lyrics_array = [lyrics + ' ' for section,lyrics in split_lyrics]\n",
    "    try:\n",
    "        tfidf_ngram_vec = tfidf_ngram_vectorizer.transform(lyrics_array)\n",
    "        svd_ngram_vec = svd_ngram.transform(tfidf_ngram_vec)\n",
    "        assert len(svd_ngram_vec) == len(sections_array)\n",
    "        assert len(svd_ngram_vec[0]) == 500\n",
    "        return list(zip(sections_array, svd_ngram_vec))\n",
    "    except ValueError:\n",
    "        log('ValueError' + str(len(sections_array)) + '\\t' + str([len(lyrics) for lyrics in lyrics_array]))\n",
    "        return list(zip(sections_array, np.array([[0]*500]*len(split_lyrics))))\n",
    "\n",
    "# Turn the split string data into tuples of section strings and TFIDF encoded lyrics of that section\n",
    "log('Splitting the encoding string lyrics of each section')\n",
    "log('\\tTesting set')\n",
    "split_encoded_test = split_string_test\n",
    "split_encoded_test['lyrics'] = split_string_test['lyrics'].map(split_lyrics_encode)\n",
    "log('\\tTraining set')\n",
    "split_encoded_train = split_string_train\n",
    "split_encoded_train['lyrics'] = split_string_train['lyrics'].map(split_lyrics_encode)\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "17:42:25 - Saving split encoded lyrics as pickles\n17:42:32 - Done\n\n"
    }
   ],
   "source": [
    "log('Saving split encoded lyrics as pickles')\n",
    "split_encoded_train.to_pickle('section_train_test/split_encoded_train.zip')\n",
    "split_encoded_test.to_pickle('section_train_test/split_encoded_test.zip')\n",
    "log('Done\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:43:10 - Reading split encoded lyrics pickles into dataframes\n21:43:12 - Done\n\n"
    }
   ],
   "source": [
    "log('Reading split encoded lyrics pickles into dataframes')\n",
    "split_encoded_train = pd.read_pickle('section_train_test/split_encoded_train.zip')\n",
    "split_encoded_test = pd.read_pickle('section_train_test/split_encoded_test.zip')\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectionSplitClassifier:\n",
    "    def __init__(self, section_classifiers, weights):\n",
    "        if section_classifiers:\n",
    "            try: self.section_classifiers = {key:value for key,value in section_classifiers.items()}\n",
    "            except AttributeError: raise ValueError('section_classifiers was not a dictionary')\n",
    "        else: raise ValueError('section_classifiers was None')\n",
    "        if weights:\n",
    "            if np.round(np.sum([weight for weight in weights.values()])) == 1:\n",
    "                try: self.weights = {key:value for key,value in weights.items()}\n",
    "                except AttributeError: raise ValueError('weights was not a dictionary')\n",
    "            else: raise ValueError('weights did not sum to 1')\n",
    "        else: raise ValueError('weights was None')\n",
    "\n",
    "\n",
    "    def set_section_classifiers(self, section_classifiers):\n",
    "        if section_classifiers:\n",
    "            try: self.section_classifiers = {key:value for key,value in section_classifiers.items()}\n",
    "            except AttributeError: raise ValueError('section_classifiers was not a dictionary')\n",
    "        else: raise ValueError('section_classifiers was None')\n",
    "\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        if weights:\n",
    "            if np.round(np.sum([weight for weight in weights.values()])) == 1:\n",
    "                try: self.weights = {key:value for key,value in weights.items()}\n",
    "                except AttributeError: raise ValueError('weights was not a dictionary')\n",
    "            else: raise ValueError('weights did not sum to 1')\n",
    "        else: raise ValueError('weights was None')\n",
    "\n",
    "\n",
    "    def fit(self, X, y, section, verbose=0):\n",
    "        if verbose: print(f'Training {section}...')\n",
    "        self.section_classifiers[section] = self.section_classifiers[section].fit(X,y)\n",
    "        if verbose: print(f'Done training {section}')\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        def predict_section(self, X_section, section):\n",
    "            def str_to_array(string, weight):\n",
    "                return float(weight) * np.array([\n",
    "                    int(string == 'country'), \n",
    "                    int(string == 'hiphop'),\n",
    "                    int(string == 'pop'), \n",
    "                    int(string == 'rock')])\n",
    "            return [str_to_array(pred, self.weights[section]) for pred in self.section_classifiers[section].predict([X_section])]\n",
    "\n",
    "        def predict_song(self, split_encoded):\n",
    "            def array_to_str(array):\n",
    "                return ['country','hiphop','pop','rock'][np.argmax(array)]\n",
    "            pred = np.array([0,0,0,0])\n",
    "            for section,encoding in split_encoded:\n",
    "                pred = np.sum([pred, predict_section(self, encoding, section)], axis=0)\n",
    "            return array_to_str(pred)\n",
    "\n",
    "        preds = [predict_song(self, lyrics) for lyrics in X]\n",
    "        assert len(preds) == len(X)\n",
    "        return(preds)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the different kinds of section classifiers and their respective song classifiers\n",
    "section_rf_classifiers = {\n",
    "    header:RandomForestClassifier(criterion='entropy', ccp_alpha=0.0175) for header in section_headers}\n",
    "section_rf_classifier = SectionSplitClassifier(section_rf_classifiers, corpus_weights)\n",
    "\n",
    "section_ada_classifiers = {\n",
    "    header:OneVsRestClassifier(AdaBoostClassifier(), n_jobs=-1) for header in section_headers}\n",
    "section_ada_classifier = SectionSplitClassifier(section_ada_classifiers, corpus_weights)\n",
    "\n",
    "section_svm_classifiers = {\n",
    "    header:OneVsRestClassifier(SVC(kernel=\"linear\", C=0.025), n_jobs=-1) for header in section_headers}\n",
    "section_svm_classifier = SectionSplitClassifier(section_svm_classifiers, corpus_weights)\n",
    "\n",
    "section_knn_classifiers = {\n",
    "    header:OneVsOneClassifier(KNeighborsClassifier(3)) for header in section_headers}\n",
    "section_knn_classifier = SectionSplitClassifier(section_knn_classifiers, corpus_weights)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:43:12 - Training Random Forest classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n21:45:34 - Done\n\n21:45:34 - Training ADA Boost classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n21:48:27 - Done\n\n21:48:27 - Training Linear SVM classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n21:50:54 - Done\n\n21:50:54 - Training k-Nearest Neighbors classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n21:51:06 - Done\n\n"
    }
   ],
   "source": [
    "# train each kind of song classifier\n",
    "log('Training Random Forest classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_rf_classifier.fit(tfidf_train[header].drop(columns=['y']), tfidf_train[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training ADA Boost classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_ada_classifier.fit(tfidf_train[header].drop(columns=['y']), tfidf_train[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training Linear SVM classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_svm_classifier.fit(tfidf_train[header].drop(columns=['y']), tfidf_train[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training k-Nearest Neighbors classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_knn_classifier.fit(tfidf_train[header].drop(columns=['y']), tfidf_train[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_write_results(filename, classifier_name, classifier, X_train, X_test, verbose=1):\n",
    "    results_file = open(filename, 'a')\n",
    "    if verbose: log(f'Predicting results for {classifier_name}')\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    if verbose: log('Done\\n')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Training Set Accuracy: {accuracy_score(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "        print(f'Classification Report Training Set:\\n{classification_report(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "        print(f'Confusion Matrix Training Set:\\n{confusion_matrix(split_encoded_train[\"genre\"], y_pred_train)}\\n')\n",
    "        print(f'Testing Set Accuracy: {accuracy_score(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "        print(f'Classification Report Testing Set:\\n{classification_report(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "        print(f'Confusion Matrix Testing Set:\\n{confusion_matrix(split_encoded_test[\"genre\"], y_pred_test)}\\n')\n",
    "\n",
    "    results_file.write(f'Results for {classifier_name}\\n')\n",
    "    results_file.write(f'Training Set Accuracy: {accuracy_score(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "    results_file.write(f'Classification Report Training Set:\\n{classification_report(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "    results_file.write(f'Confusion Matrix Training Set:\\n{confusion_matrix(split_encoded_train[\"genre\"], y_pred_train)}\\n')\n",
    "    results_file.write(f'Testing Set Accuracy: {accuracy_score(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "    results_file.write(f'Classification Report Testing Set:\\n{classification_report(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "    results_file.write(f'Confusion Matrix Testing Set:\\n{confusion_matrix(split_encoded_test[\"genre\"], y_pred_test)}\\n')\n",
    "    results_file.write(str('-' * 30) + '\\n')\n",
    "    results_file.close()\n",
    "\n",
    "    return y_pred_train, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21:55:12 - start\n21:55:12 - Predicting results for Random Forest Classifier\n22:02:02 - Done\n\nTraining Set Accuracy: 0.49771341463414637\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.73      0.30      0.42       738\n      hiphop       0.47      0.83      0.60      1131\n         pop       0.49      0.81      0.62       973\n        rock       0.42      0.01      0.01      1094\n\n    accuracy                           0.50      3936\n   macro avg       0.53      0.49      0.41      3936\nweighted avg       0.51      0.50      0.41      3936\n\nConfusion Matrix Training Set:\n[[220  42 476   0]\n [ 12 939 172   8]\n [ 62 116 792   3]\n [  9 915 162   8]]\n\nTesting Set Accuracy: 0.4751269035532995\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.75      0.29      0.42       199\n      hiphop       0.43      0.87      0.57       255\n         pop       0.49      0.79      0.60       239\n        rock       0.00      0.00      0.00       292\n\n    accuracy                           0.48       985\n   macro avg       0.42      0.49      0.40       985\nweighted avg       0.38      0.48      0.38       985\n\nConfusion Matrix Testing Set:\n[[ 58  17 123   1]\n [  0 222  33   0]\n [ 16  33 188   2]\n [  3 246  43   0]]\n\n22:02:02 - rf prediction done\n"
    }
   ],
   "source": [
    "# predict the genres of both training and testing sets\n",
    "log('start')\n",
    "y_pred_train_rf, y_pred_test_rf = predict_write_results('eval_tfidf_section.txt', 'Random Forest Classifier', section_rf_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('rf prediction done')\n",
    "# y_pred_train_ada = section_ada_classifier.predict(split_encoded_train['lyrics'])\n",
    "# y_pred_test_ada = section_ada_classifier.predict(split_encoded_test['lyrics'])\n",
    "# log('ada prediction done')\n",
    "# y_pred_train_svm = section_svm_classifier.predict(split_encoded_train['lyrics'])\n",
    "# y_pred_test_svm = section_svm_classifier.predict(split_encoded_test['lyrics'])\n",
    "# log('svm prediction done')\n",
    "# y_pred_train_knn = section_knn_classifier.predict(split_encoded_train['lyrics'])\n",
    "# y_pred_test_knn = section_knn_classifier.predict(split_encoded_test['lyrics'])\n",
    "# log('knn prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:02:02 - start\n22:02:02 - Predicting results for ADA Boost Classifier\n22:21:32 - Done\n\nTraining Set Accuracy: 0.5510670731707317\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.71      0.66      0.68       738\n      hiphop       0.47      0.48      0.48      1131\n         pop       0.60      0.69      0.64       973\n        rock       0.47      0.43      0.45      1094\n\n    accuracy                           0.55      3936\n   macro avg       0.57      0.56      0.56      3936\nweighted avg       0.55      0.55      0.55      3936\n\nConfusion Matrix Training Set:\n[[485  19 213  21]\n [ 23 547 123 438]\n [149  86 671  67]\n [ 23 502 103 466]]\n\nTesting Set Accuracy: 0.4984771573604061\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.74      0.62      0.67       199\n      hiphop       0.36      0.38      0.37       255\n         pop       0.58      0.71      0.64       239\n        rock       0.39      0.35      0.37       292\n\n    accuracy                           0.50       985\n   macro avg       0.52      0.51      0.51       985\nweighted avg       0.50      0.50      0.50       985\n\nConfusion Matrix Testing Set:\n[[123   8  58  10]\n [  6  98  22 129]\n [ 31  21 169  18]\n [  6 143  42 101]]\n\n22:21:33 - ada prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_ada, y_pred_test_ada = predict_write_results('eval_tfidf_section.txt', 'ADA Boost Classifier', section_ada_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('ada prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:21:33 - start\n22:21:33 - Predicting results for Linear SVM Classifier\n22:29:11 - Done\n\nTraining Set Accuracy: 0.45147357723577236\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.46      0.80      0.58       738\n      hiphop       0.47      0.28      0.35      1131\n         pop       0.44      0.65      0.52       973\n        rock       0.46      0.21      0.29      1094\n\n    accuracy                           0.45      3936\n   macro avg       0.45      0.49      0.44      3936\nweighted avg       0.46      0.45      0.42      3936\n\nConfusion Matrix Training Set:\n[[594  14 120  10]\n [233 313 357 228]\n [247  53 636  37]\n [229 293 338 234]]\n\nTesting Set Accuracy: 0.4416243654822335\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.46      0.82      0.59       199\n      hiphop       0.40      0.25      0.31       255\n         pop       0.44      0.64      0.52       239\n        rock       0.43      0.18      0.26       292\n\n    accuracy                           0.44       985\n   macro avg       0.43      0.47      0.42       985\nweighted avg       0.43      0.44      0.40       985\n\nConfusion Matrix Testing Set:\n[[163   1  30   5]\n [ 59  65  71  60]\n [ 66  13 153   7]\n [ 63  85  90  54]]\n\n22:29:11 - svm prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_svm, y_pred_test_svm = predict_write_results('eval_tfidf_section.txt', 'Linear SVM Classifier', section_svm_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('svm prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:29:11 - start\n22:29:11 - Predicting results for k-Nearest Neighbor Classifier\n23:07:16 - Done\n\nTraining Set Accuracy: 0.3788109756097561\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.29      0.84      0.43       738\n      hiphop       0.37      0.09      0.15      1131\n         pop       0.55      0.58      0.56       973\n        rock       0.42      0.18      0.25      1094\n\n    accuracy                           0.38      3936\n   macro avg       0.41      0.42      0.35      3936\nweighted avg       0.41      0.38      0.33      3936\n\nConfusion Matrix Training Set:\n[[621  45  38  34]\n [623 107 219 182]\n [297  48 565  63]\n [598  86 212 198]]\n\nTesting Set Accuracy: 0.24873096446700507\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.25      0.69      0.36       199\n      hiphop       0.18      0.07      0.10       255\n         pop       0.27      0.21      0.23       239\n        rock       0.27      0.14      0.19       292\n\n    accuracy                           0.25       985\n   macro avg       0.24      0.28      0.22       985\nweighted avg       0.24      0.25      0.21       985\n\nConfusion Matrix Testing Set:\n[[137  15  32  15]\n [132  17  49  57]\n [128  24  50  37]\n [157  38  56  41]]\n\n23:07:16 - knn prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_knn, y_pred_test_knn = predict_write_results('eval_tfidf_section.txt', 'k-Nearest Neighbor Classifier', section_knn_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('knn prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:23:31 - Training Random Forest classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n23:26:19 - Done\n\n23:26:19 - Training ADA Boost classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n23:30:17 - Done\n\n23:30:17 - Training Linear SVM classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n23:33:55 - Done\n\n23:33:55 - Training k-Nearest Neighbors classifier with all sections\nTraining Intro...\nDone training Intro\nTraining Verse...\nDone training Verse\nTraining Refrain...\nDone training Refrain\nTraining Pre-Chorus...\nDone training Pre-Chorus\nTraining Chorus...\nDone training Chorus\nTraining Post-Chorus...\nDone training Post-Chorus\nTraining Hooks...\nDone training Hooks\nTraining Riffs/Basslines...\nDone training Riffs/Basslines\nTraining Scratches...\nDone training Scratches\nTraining Sampling...\nDone training Sampling\nTraining Bridge...\nDone training Bridge\nTraining Interlude...\nDone training Interlude\nTraining Skit...\nDone training Skit\nTraining Collision...\nDone training Collision\nTraining Instrumental...\nDone training Instrumental\nTraining Solo...\nDone training Solo\nTraining Ad-lib...\nDone training Ad-lib\nTraining Segue...\nDone training Segue\nTraining Outro...\nDone training Outro\n23:34:09 - Done\n\n"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# train each kind of song classifier on WHOLE CORPUS \n",
    "# to find an UPPER BOUND performance metric\n",
    "tfidf_full = {header:pd.concat([tfidf_train[header], tfidf_test[header]]) for header in section_headers}\n",
    "\n",
    "log('Training Random Forest classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_rf_classifier.fit(tfidf_full[header].drop(columns=['y']), tfidf_full[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training ADA Boost classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_ada_classifier.fit(tfidf_full[header].drop(columns=['y']), tfidf_full[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training Linear SVM classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_svm_classifier.fit(tfidf_full[header].drop(columns=['y']), tfidf_full[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    "\n",
    "log('Training k-Nearest Neighbors classifier with all sections')\n",
    "for header in section_headers:\n",
    "    section_knn_classifier.fit(tfidf_full[header].drop(columns=['y']), tfidf_full[header]['y'], header, verbose=1)\n",
    "log('Done\\n')\n",
    ""
=======
    "def show_results(y_pred_train, y_pred_test):\n",
    "    print(f'Training Set Accuracy: {accuracy_score(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "    print(f'Classification Report Training Set:\\n{classification_report(split_encoded_train[\"genre\"], y_pred_train)}')\n",
    "    print('-' * 20)\n",
    "    print(f'Confusion Matrix Training Set:\\n{confusion_matrix(split_encoded_train[\"genre\"], y_pred_train)}\\n')\n",
    "    \n",
    "    print(f'Testing Set Accuracy: {accuracy_score(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "    print(f'Classification Report Testing Set:\\n{classification_report(split_encoded_test[\"genre\"], y_pred_test)}')\n",
    "    print('-' * 20)\n",
    "    print(f'Confusion Matrix Testing Set:\\n{confusion_matrix(split_encoded_test[\"genre\"], y_pred_test)}\\n')\n",
    "",
    "y_pred_trains = [y_pred_train_rf, y_pred_train_ada, y_pred_train_svm, y_pred_train_knn]\n",
    "y_pred_tests = [y_pred_test_rf, y_pred_test_ada, y_pred_test_svm, y_pred_test_knn]\n",
    "",
    "for train, test in zip(y_pred_trains, y_pred_tests):\n",
    "    show_results(train, test)"    
>>>>>>> 85d2f161834999cf11c749077f641473e7e9890f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('eval_tfidf_section.txt', 'a')\n",
    "results_file.write(str('-' * 30) + '\\n')\n",
    "results_file.write(str('-' * 30) + '\\n')\n",
    "results_file.write('\\nTRAINING AND TESTING USING WHOLE CORPUS TO GET UPPERBOUND PERFORMANCE\\nRESULTS BELOW\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:34:09 - start\n23:34:09 - Predicting results for Random Forest Classifier\n23:40:09 - Done\n\nTraining Set Accuracy: 0.49822154471544716\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.72      0.34      0.46       738\n      hiphop       0.47      0.51      0.49      1131\n         pop       0.50      0.80      0.62       973\n        rock       0.44      0.33      0.37      1094\n\n    accuracy                           0.50      3936\n   macro avg       0.53      0.49      0.49      3936\nweighted avg       0.52      0.50      0.48      3936\n\nConfusion Matrix Training Set:\n[[250  20 444  24]\n [ 13 576 162 380]\n [ 76  64 777  56]\n [  9 566 161 358]]\n\nTesting Set Accuracy: 0.49949238578680205\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.73      0.35      0.47       199\n      hiphop       0.44      0.52      0.48       255\n         pop       0.50      0.77      0.60       239\n        rock       0.49      0.36      0.41       292\n\n    accuracy                           0.50       985\n   macro avg       0.54      0.50      0.49       985\nweighted avg       0.53      0.50      0.49       985\n\nConfusion Matrix Testing Set:\n[[ 69  10 111   9]\n [  1 133  38  83]\n [ 20  15 185  19]\n [  5 143  39 105]]\n\n23:40:10 - rf prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_rf, y_pred_test_rf = predict_write_results('eval_tfidf_section.txt', 'Random Forest Classifier', section_rf_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('rf prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:40:10 - start\n23:40:10 - Predicting results for ADA Boost Classifier\n23:57:07 - Done\n\nTraining Set Accuracy: 0.5353150406504065\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.67      0.67      0.67       738\n      hiphop       0.47      0.37      0.41      1131\n         pop       0.57      0.72      0.64       973\n        rock       0.45      0.45      0.45      1094\n\n    accuracy                           0.54      3936\n   macro avg       0.54      0.55      0.54      3936\nweighted avg       0.53      0.54      0.53      3936\n\nConfusion Matrix Training Set:\n[[496  11 209  22]\n [ 40 417 168 506]\n [167  42 703  61]\n [ 37 410 156 491]]\n\nTesting Set Accuracy: 0.5543147208121827\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.71      0.72      0.72       199\n      hiphop       0.46      0.41      0.43       255\n         pop       0.59      0.73      0.65       239\n        rock       0.48      0.42      0.45       292\n\n    accuracy                           0.55       985\n   macro avg       0.56      0.57      0.56       985\nweighted avg       0.55      0.55      0.55       985\n\nConfusion Matrix Testing Set:\n[[144   5  41   9]\n [  9 104  33 109]\n [ 38   8 174  19]\n [ 12 111  45 124]]\n\n23:57:07 - ada prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_ada, y_pred_test_ada = predict_write_results('eval_tfidf_section.txt', 'ADA Boost Classifier', section_ada_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('ada prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "23:57:07 - start\n23:57:07 - Predicting results for Linear SVM Classifier\n00:06:28 - Done\n\nTraining Set Accuracy: 0.4339430894308943\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.43      0.83      0.56       738\n      hiphop       0.45      0.42      0.43      1131\n         pop       0.43      0.63      0.51       973\n        rock       0.47      0.01      0.01      1094\n\n    accuracy                           0.43      3936\n   macro avg       0.44      0.47      0.38      3936\nweighted avg       0.45      0.43      0.36      3936\n\nConfusion Matrix Training Set:\n[[610  25 103   0]\n [282 473 369   7]\n [267  87 617   2]\n [271 459 356   8]]\n\nTesting Set Accuracy: 0.449746192893401\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.45      0.85      0.59       199\n      hiphop       0.43      0.46      0.45       255\n         pop       0.46      0.65      0.54       239\n        rock       0.33      0.00      0.01       292\n\n    accuracy                           0.45       985\n   macro avg       0.42      0.49      0.40       985\nweighted avg       0.41      0.45      0.37       985\n\nConfusion Matrix Testing Set:\n[[170   7  22   0]\n [ 64 117  72   2]\n [ 69  15 155   0]\n [ 75 131  85   1]]\n\n00:06:29 - svm prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_svm, y_pred_test_svm = predict_write_results('eval_tfidf_section.txt', 'Linear SVM Classifier', section_svm_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('svm prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "00:06:29 - start\n00:06:29 - Predicting results for k-Nearest Neighbor Classifier\n00:49:53 - Done\n\nTraining Set Accuracy: 0.40497967479674796\nClassification Report Training Set:\n              precision    recall  f1-score   support\n\n     country       0.39      0.51      0.44       738\n      hiphop       0.41      0.37      0.39      1131\n         pop       0.55      0.58      0.56       973\n        rock       0.26      0.21      0.23      1094\n\n    accuracy                           0.40      3936\n   macro avg       0.40      0.42      0.41      3936\nweighted avg       0.40      0.40      0.40      3936\n\nConfusion Matrix Training Set:\n[[378 100  43 217]\n [254 421 212 244]\n [ 92 111 561 209]\n [252 405 203 234]]\n\nTesting Set Accuracy: 0.4101522842639594\nClassification Report Testing Set:\n              precision    recall  f1-score   support\n\n     country       0.45      0.54      0.49       199\n      hiphop       0.37      0.39      0.38       255\n         pop       0.55      0.55      0.55       239\n        rock       0.28      0.23      0.25       292\n\n    accuracy                           0.41       985\n   macro avg       0.41      0.43      0.42       985\nweighted avg       0.40      0.41      0.40       985\n\nConfusion Matrix Testing Set:\n[[107  26  13  53]\n [ 56  99  44  56]\n [ 18  29 132  60]\n [ 58 115  53  66]]\n\n00:49:54 - knn prediction done\n"
    }
   ],
   "source": [
    "log('start')\n",
    "y_pred_train_knn, y_pred_test_knn = predict_write_results('eval_tfidf_section.txt', 'k-Nearest Neighbor Classifier', section_knn_classifier, split_encoded_train['lyrics'], split_encoded_test['lyrics'], verbose=1)\n",
    "log('knn prediction done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}